{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "import re\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"3\"\n",
    "\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Embedding, LSTM, Bidirectional, Dense, Input, Masking, Lambda\n",
    "import keras.backend as K\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import LambdaCallback, LearningRateScheduler, Callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_train_val(filename, val_prob=0.1):\n",
    "    with open(filename, \"rb\") as handler:\n",
    "        train_X, train_Y, val_X, val_Y = [], [], [], []\n",
    "        for line in handler:\n",
    "            x, y = line.decode(\"utf-8\").strip().lower().split(\"\\t\")\n",
    "            x = re.sub(\"\\W\", \" \", x)\n",
    "            if np.random.uniform() > val_prob:\n",
    "                train_X.append(x)\n",
    "                train_Y.append(y)\n",
    "            else:\n",
    "                val_X.append(x)\n",
    "                val_Y.append(y)\n",
    "        return np.array(train_X), np.array(train_Y), np.array(val_X), np.array(val_Y)\n",
    "\n",
    "def read_test(filename):\n",
    "    with open(filename, \"rb\") as handler:\n",
    "        X = []\n",
    "        for line in handler:\n",
    "            line = re.sub(\"\\W\", \" \", line.decode(\"utf-8\").strip().lower())\n",
    "            x = line.strip().lower()\n",
    "            X.append(re.sub(\"\\W\", \" \", x))\n",
    "        return np.array(X)\n",
    "\n",
    "def acc_metric(labels, predictions):\n",
    "    assert isinstance(labels, np.ndarray)\n",
    "    assert isinstance(predictions, np.ndarray)\n",
    "    return len(labels[labels == predictions]) / len(labels)\n",
    "\n",
    "def meashure_model(model, X, Y):\n",
    "    kf = KFold(n_splits=2)\n",
    "    metrics = []\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        train_X, test_X = X[train_index], X[test_index]\n",
    "        train_Y, test_Y = Y[train_index], Y[test_index]\n",
    "        model.fit(train_X, train_Y)\n",
    "        predictions = model.predict(test_X)\n",
    "        metrics.append(acc_metric(predictions, test_Y))\n",
    "    return np.mean(metrics), np.var(metrics)\n",
    "\n",
    "class MostPopularModel:\n",
    "    def fit(self, X, Y):\n",
    "        self._answer = Counter(Y).most_common()[0][0]\n",
    "\n",
    "    def predict(self, X):\n",
    "        return np.array([self._answer] * len(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_FILENAME = \"names_and_rubrics_learn.tsv\"\n",
    "TEST_FILENAME = \"names_and_rubrics_test_no_rubric.tsv\"\n",
    "MIN_FREQ = 5\n",
    "\n",
    "TOKENS_NUM = 150767\n",
    "HIDDEN_DIM = 256\n",
    "MAX_LEN = 45\n",
    "LSTM_NUM = 2\n",
    "HIDDEN_LAYESR_NUM = 2\n",
    "BATCH_SIZE = 1025\n",
    "LABELS_NUM = 1222\n",
    "ACTIVATION = 'tanh'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, train_Y, val_X, val_Y = read_train_val(TRAIN_FILENAME)\n",
    "test_X = read_test(TEST_FILENAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8026179, 8026179, 890923, 890923, 1000000)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_X), len(train_Y), len(val_X), len(val_Y), len(test_X)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "most_popular_model = MostPopularModel()\n",
    "mean, var = meashure_model(most_popular_model, train_X, train_Y)\n",
    "print(mean, var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_tokens_counter(*datas):\n",
    "    tokens_counter = Counter()\n",
    "    for lines in datas:\n",
    "        for line in lines:\n",
    "            for word in line.split():\n",
    "                tokens_counter[word] += 1\n",
    "    return tokens_counter\n",
    "\n",
    "def make_index_by_token(tokens_counter, min_freq):\n",
    "    tokens = [token for token in tokens_counter if tokens_counter[token] > min_freq]\n",
    "    return {\n",
    "        token: i\n",
    "        for i, token in enumerate(tokens)\n",
    "    }\n",
    "\n",
    "def make_label_by_y(*Ys):\n",
    "    all_Y = set()\n",
    "    for Y in Ys:\n",
    "        all_Y.update(Y)\n",
    "    return {\n",
    "        y: i\n",
    "        for i, y in enumerate(set(all_Y))\n",
    "    }\n",
    "\n",
    "def make_indices_by_label(Y, X, label_by_y, index_by_token):\n",
    "    indices_by_label = {\n",
    "        label_by_y[y]: []\n",
    "        for y in set(Y)\n",
    "    }\n",
    "    for x, y in zip(X, Y):\n",
    "        indices_by_label[label_by_y[y]].append(make_indices_from_x(x, index_by_token))\n",
    "    return indices_by_label\n",
    "\n",
    "def get_max_X_len(*Xs):\n",
    "    max_len = -1\n",
    "    for X in Xs:\n",
    "        max_len = max(max_len, max([len(x.split()) for x in X]))\n",
    "    return max_len\n",
    "\n",
    "def make_indices_from_x(x, index_by_token):\n",
    "    return [\n",
    "        index_by_token[token]\n",
    "        for token in x.split()\n",
    "        if token in index_by_token\n",
    "    ]\n",
    "\n",
    "def make_positives_data_gen(X, Y, label_by_y, index_by_token):\n",
    "    def positives_data_gen():\n",
    "        while True:\n",
    "            index = np.random.randint(0, len(X))\n",
    "            yield (\n",
    "                make_indices_from_x(X[index], index_by_token),\n",
    "                label_by_y[Y[index]]\n",
    "            )\n",
    "    return positives_data_gen()\n",
    "\n",
    "def make_nagative(label, labels_nd_array, indices_by_label):\n",
    "    negative_label = label\n",
    "    while negative_label == label:\n",
    "        negative_label = np.random.choice(labels_nd_array)\n",
    "    variants = indices_by_label[negative_label]\n",
    "    index = np.random.randint(0, len(variants))\n",
    "    return variants[index]\n",
    "\n",
    "def make_data_gen(X, Y, label_by_y, index_by_token, indices_by_label, half_batch_size):\n",
    "    labels_nd_array = np.array([label_by_y[y] for y in set(Y)])\n",
    "    positive_data_gen = make_positives_data_gen(X, Y, label_by_y, index_by_token)\n",
    "    labels_eye = np.eye(len(label_by_y))\n",
    "    outputs = np.array([1] * half_batch_size + [-1] * half_batch_size)\n",
    "    def data_gen():\n",
    "        while True:\n",
    "            positive_labels = []\n",
    "            names_inputs = np.zeros([half_batch_size * 2, MAX_LEN])\n",
    "            for i in range(half_batch_size):\n",
    "                positive_tokens_indices, label = next(positive_data_gen)                \n",
    "                names_inputs[i, :len(positive_tokens_indices)] = positive_tokens_indices\n",
    "                positive_labels.append(label)\n",
    "            negative_labels = []\n",
    "            for i, label in enumerate(positive_labels):\n",
    "                negative_tokens_indices = make_nagative(label, labels_nd_array, indices_by_label)\n",
    "                names_inputs[half_batch_size + i, :len(negative_tokens_indices)] = negative_tokens_indices\n",
    "                negative_labels.append(label)\n",
    "                \n",
    "            yield (\n",
    "                {'name_input': names_inputs, 'label_input': labels_eye[positive_labels + negative_labels]},\n",
    "                {'output': outputs}\n",
    "            )\n",
    "    return data_gen()\n",
    "\n",
    "\n",
    "def make_classification_data_gen(X, Y, label_by_y, index_by_token, batch_size):\n",
    "    labels_nd_array = np.array([label_by_y[y] for y in set(Y)])\n",
    "    positive_data_gen = make_positives_data_gen(X, Y, label_by_y, index_by_token)\n",
    "    labels_eye = np.eye(len(label_by_y))\n",
    "    def data_gen():\n",
    "        while True:\n",
    "            labels = []\n",
    "            inputs = np.zeros([batch_size, MAX_LEN])\n",
    "            for i in range(batch_size):\n",
    "                positive_tokens_indices, label = next(positive_data_gen)                \n",
    "                inputs[i, :len(positive_tokens_indices)] = positive_tokens_indices\n",
    "                labels.append(label)\n",
    "                \n",
    "            yield inputs, labels_eye[labels]\n",
    "    return data_gen()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_by_y = make_label_by_y(train_Y, val_Y)\n",
    "tokens_counter = make_tokens_counter(train_X, val_X, test_X)\n",
    "index_by_token = make_index_by_token(tokens_counter, MIN_FREQ)\n",
    "indices_by_label_train = make_indices_by_label(train_Y, train_X, label_by_y, index_by_token)\n",
    "indices_by_label_val = make_indices_by_label(val_Y, val_X, label_by_y, index_by_token)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "train_data = make_data_gen(\n",
    "    train_X,\n",
    "    train_Y,\n",
    "    label_by_y,\n",
    "    index_by_token,\n",
    "    indices_by_label_train,\n",
    "    int(BATCH_SIZE / 2)\n",
    ")\n",
    "val_data = make_data_gen(\n",
    "    val_X,\n",
    "    val_Y,\n",
    "    label_by_y,\n",
    "    index_by_token,\n",
    "    indices_by_label_val,\n",
    "    int(BATCH_SIZE / 2)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_cosine_proximity(y_true, y_pred):\n",
    "    return -K.mean(y_pred * y_true)\n",
    "\n",
    "def mean_positive_score(y_true, y_pred):\n",
    "    filter_mult = (y_true + 1) / 2\n",
    "    return K.mean(y_pred * filter_mult)\n",
    "\n",
    "def mean_positive_var(y_true, y_pred):\n",
    "    mean_positive = mean_positive_score(y_true, y_pred)\n",
    "    filter_mult = (y_true + 1) / 2\n",
    "    return K.mean((y_pred * filter_mult - mean_positive) ** 2)\n",
    "\n",
    "def get_pred(y_true, y_pred):\n",
    "    mean_positive = mean_positive_score(y_true, y_pred)\n",
    "    mean_negative = mean_negative_score(y_true, y_pred)\n",
    "    \n",
    "    threshold = (mean_positive + mean_negative) / 2\n",
    "    \n",
    "    positive_mult = (y_true + 1) / 2\n",
    "    negative_mult = (1 - y_true) / 2\n",
    "\n",
    "    return K.mean((y_pred * filter_mult - mean_positive) ** 2)\n",
    "\n",
    "def mean_negative_score(y_true, y_pred):\n",
    "    filter_mult = (1 - y_true) / 2\n",
    "    return K.mean(y_pred * filter_mult)\n",
    "\n",
    "def mean_negative_var(y_true, y_pred):\n",
    "    mean_negative = mean_negative_score(y_true, y_pred)\n",
    "    filter_mult = (1 - y_true) / 2\n",
    "    return K.mean((y_pred * filter_mult - mean_negative) ** 2)\n",
    "\n",
    "def normalize(embedding):\n",
    "    return K.l2_normalize(embedding, axis=-1)\n",
    "\n",
    "def dot_product(embeddings):\n",
    "    return K.sum(embeddings[0] * embeddings[1], axis=-1)\n",
    "\n",
    "def reshape_to_prediction(score):\n",
    "    return K.reshape(score, (-1, 1))\n",
    "\n",
    "def make_dssm_predictions(X, y_set, model, label_by_y, index_by_token, limit):\n",
    "    labels_eye = np.eye(len(y_set))\n",
    "    labels = labels_eye[[label_by_y[y] for y in y_set]]\n",
    "    predictions = []\n",
    "    for x in X[:limit]:\n",
    "        names_input = np.zeros(MAX_LEN)\n",
    "        indices = make_indices_from_x(x, index_by_token)\n",
    "        names_input[:len(indices)] = indices\n",
    "        names_input = names_input.reshape([1, MAX_LEN]).repeat(len(labels), axis=0)\n",
    "        scores = model.predict({\"name_input\": names_input, \"label_input\": labels}).reshape(-1)\n",
    "        predictions.append(np.argmax(scores))\n",
    "        print(scores[predictions[-1]])\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "name_input = Input(shape=(MAX_LEN,), name=\"name_input\")  # shape: (BATCH_SIZE, MAX_LEN)\n",
    "masked = Masking(mask_value=0)(name_input)\n",
    "encoded = Embedding(TOKENS_NUM, HIDDEN_DIM)(masked)  # shape: (BATCH_SIZE, MAX_LEN, HIDDEN_DIM)\n",
    "for i in range(LSTM_NUM - 1):\n",
    "    encoded = Bidirectional(LSTM(HIDDEN_DIM, return_sequences=True))(encoded)  # shape: (BATCH_SIZE, HIDDEN_DIM)\n",
    "hidden = Bidirectional(LSTM(HIDDEN_DIM))(encoded)  # shape: (BATCH_SIZE, HIDDEN_DIM)\n",
    "for i in range(HIDDEN_LAYESR_NUM):\n",
    "    hidden = Dense(HIDDEN_DIM, activation=ACTIVATION)(hidden)  # shape: (BATCH_SIZE, HIDDEN_DIM)\n",
    "name_embedding =  Lambda(normalize)(hidden)  # shape: (BATCH_SIZE, HIDDEN_DIM)\n",
    "\n",
    "label_input = Input(shape=(LABELS_NUM,), name=\"label_input\")  # shape: (BATCH_SIZE, LABELS_NUM)\n",
    "hidden = Dense(HIDDEN_DIM, activation=ACTIVATION)(label_input)  # shape: (BATCH_SIZE, HIDDEN_DIM)\n",
    "for i in range(HIDDEN_LAYESR_NUM - 1):\n",
    "    hidden = Dense(HIDDEN_DIM, activation=ACTIVATION)(hidden)  # shape: (BATCH_SIZE, HIDDEN_DIM)\n",
    "label_embedding = Lambda(normalize)(hidden)  # shape: (BATCH_SIZE, HIDDEN_DIM)\n",
    "\n",
    "score = Lambda(dot_product)([label_embedding, name_embedding])\n",
    "prediction = Lambda(reshape_to_prediction, name=\"output\")(score)\n",
    "\n",
    "model = Model(inputs=[label_input, name_input], outputs=prediction)\n",
    "model.compile(\n",
    "    Adam(),\n",
    "    loss=my_cosine_proximity,\n",
    "    metrics=[mean_positive_score, mean_negative_score, mean_positive_var, mean_negative_var, 'acc']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EvaluateCallback(Callback):\n",
    "    def __init__(self,\n",
    "                 model,\n",
    "                 models_folder,\n",
    "                 metrics_file,\n",
    "                 train_generator,\n",
    "                 test_generator,\n",
    "                 validation_steps,\n",
    "                 validation_batch_divider):\n",
    "        self._model = model\n",
    "        self._models_folder = models_folder\n",
    "        self._metrics_file = metrics_file\n",
    "        self._test_generator = test_generator\n",
    "        self._train_generator = train_generator\n",
    "        self._validation_steps = validation_steps\n",
    "        self._validation_batch_divider = validation_batch_divider\n",
    "        self._epoch = 0\n",
    "\n",
    "        self.history = {}\n",
    "        for name in self._model.metrics_names:\n",
    "            self.history[\"train_\" + name] = []\n",
    "            self.history[\"test_\" + name] = []\n",
    "            \n",
    "    def on_train_begin(self, logs):\n",
    "        if os.path.exists(self._models_folder):\n",
    "            shutil.rmtree(self._models_folder)\n",
    "            os.mkdir(self._models_folder)\n",
    "        if os.path.exists(self._metrics_file):\n",
    "            os.remove(self._metrics_file)\n",
    "            open(self._metrics_file, \"w\").close()\n",
    "\n",
    "    def on_batch_end(self, batch, logs):\n",
    "        if batch % self._validation_batch_divider == 0:\n",
    "            test_evals = self._model.evaluate_generator(\n",
    "                self._test_generator,\n",
    "                steps=self._validation_steps\n",
    "            )\n",
    "            train_evals = self._model.evaluate_generator(\n",
    "                self._train_generator,\n",
    "                steps=self._validation_steps\n",
    "            )\n",
    "            for metric_name, metric in zip(self._model.metrics_names, train_evals):\n",
    "                self.history[\"train_\" + metric_name].append(metric)\n",
    "            for metric_name, metric in zip(self._model.metrics_names, test_evals):\n",
    "                self.history[\"test_\" + metric_name].append(metric)\n",
    "            short_model_name = \"epoch_{}_batch_{}\".format(\n",
    "                self._epoch,\n",
    "                batch)\n",
    "            metrics_string = short_model_name + \"_train_{}_test_{}\".format(\n",
    "                \"_\".join(map(str, train_evals)),\n",
    "                \"_\".join(map(str, test_evals))\n",
    "            )\n",
    "            with open(self._metrics_file, \"a\") as handler:\n",
    "                handler.write(metrics_string + \"\\n\")\n",
    "            \n",
    "            self._model.save_weights(os.path.join(self._models_folder, short_model_name))\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs):\n",
    "        self._epoch += 1"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "evaluate_callback = EvaluateCallback(\n",
    "    model,\n",
    "    \"logs\",\n",
    "    \"metrics.txt\",\n",
    "    train_data,\n",
    "    val_data,\n",
    "    1000,\n",
    "    1000\n",
    ")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "history = model.fit_generator(\n",
    "    train_data,\n",
    "    steps_per_epoch=int(len(train_X) / (BATCH_SIZE * 2)),\n",
    "    epochs=10,\n",
    "    verbose=1,\n",
    "    callbacks=[evaluate_callback],\n",
    "    initial_epoch=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_train_data = make_classification_data_gen(\n",
    "    train_X,\n",
    "    train_Y,\n",
    "    label_by_y,\n",
    "    index_by_token,\n",
    "    BATCH_SIZE\n",
    ")\n",
    "classification_val_data = make_classification_data_gen(\n",
    "    val_X,\n",
    "    val_Y,\n",
    "    label_by_y,\n",
    "    index_by_token,\n",
    "    BATCH_SIZE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_input = Input(shape=(MAX_LEN,))  # shape: (BATCH_SIZE, MAX_LEN)\n",
    "masked = Masking(mask_value=0)(name_input)\n",
    "encoded = Embedding(TOKENS_NUM, HIDDEN_DIM)(masked)  # shape: (BATCH_SIZE, MAX_LEN, HIDDEN_DIM)\n",
    "for i in range(LSTM_NUM - 1):\n",
    "    encoded = Bidirectional(LSTM(HIDDEN_DIM, return_sequences=True))(encoded)  # shape: (BATCH_SIZE, HIDDEN_DIM)\n",
    "hidden = Bidirectional(LSTM(HIDDEN_DIM))(encoded)  # shape: (BATCH_SIZE, HIDDEN_DIM)\n",
    "for i in range(HIDDEN_LAYESR_NUM):\n",
    "    hidden = Dense(HIDDEN_DIM, activation=ACTIVATION)(hidden)  # shape: (BATCH_SIZE, HIDDEN_DIM)\n",
    "\n",
    "for i in range(HIDDEN_LAYESR_NUM - 1):\n",
    "    hidden = Dense(HIDDEN_DIM, activation=ACTIVATION)(hidden)  # shape: (BATCH_SIZE, HIDDEN_DIM)\n",
    "scores = Dense(LABELS_NUM, activation='softmax')(hidden)  # shape: (BATCH_SIZE, LABELS_NUM)\n",
    "\n",
    "classificaton_model = Model(inputs=name_input, outputs=scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "classificaton_model.compile(\n",
    "    Adam(lr=0.001),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_callback_classification = EvaluateCallback(\n",
    "    classificaton_model,\n",
    "    \"logs_256\",\n",
    "    \"metrics_256.txt\",\n",
    "    classification_train_data,\n",
    "    classification_val_data,\n",
    "    50,\n",
    "    500\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "divide_lr_by = 10\n",
    "start_lr = 0.001\n",
    "reduce_lr_every = 5\n",
    "def learning_rate(epoch):\n",
    "    return start_lr / divide_lr_by ** (epoch / reduce_lr_every)\n",
    "lr_decay_callback = LearningRateScheduler(schedule=learning_rate, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\n",
      "Epoch 00001: LearningRateScheduler setting learning rate to 0.001.\n",
      "   1/7830 [..............................] - ETA: 10:31:25 - loss: 7.1080 - acc: 0.0000e+00"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/icecream/.local/lib/python3.5/site-packages/keras/callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (34.019213). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "   2/7830 [..............................] - ETA: 43:27:34 - loss: 7.1022 - acc: 0.0132    "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/icecream/.local/lib/python3.5/site-packages/keras/callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (17.010085). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7830/7830 [==============================] - 9156s 1s/step - loss: 2.9889 - acc: 0.4690\n",
      "Epoch 2/20\n",
      "\n",
      "Epoch 00002: LearningRateScheduler setting learning rate to 0.0006309573444801932.\n",
      "   1/7830 [..............................] - ETA: 2:23:24 - loss: 2.2826 - acc: 0.5649"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/icecream/.local/lib/python3.5/site-packages/keras/callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (33.141702). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "   2/7830 [..............................] - ETA: 38:26:28 - loss: 2.2633 - acc: 0.5712"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/icecream/.local/lib/python3.5/site-packages/keras/callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (16.571447). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7830/7830 [==============================] - 9153s 1s/step - loss: 2.0735 - acc: 0.6080\n",
      "Epoch 3/20\n",
      "\n",
      "Epoch 00003: LearningRateScheduler setting learning rate to 0.00039810717055349724.\n",
      "   1/7830 [..............................] - ETA: 2:23:58 - loss: 1.9304 - acc: 0.6283"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/icecream/.local/lib/python3.5/site-packages/keras/callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (33.042366). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "   2/7830 [..............................] - ETA: 38:19:16 - loss: 1.9350 - acc: 0.6302"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/icecream/.local/lib/python3.5/site-packages/keras/callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (16.521813). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7830/7830 [==============================] - 9156s 1s/step - loss: 1.9258 - acc: 0.6286\n",
      "Epoch 4/20\n",
      "\n",
      "Epoch 00004: LearningRateScheduler setting learning rate to 0.000251188643150958.\n",
      "   1/7830 [..............................] - ETA: 2:23:52 - loss: 1.9137 - acc: 0.6410"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/icecream/.local/lib/python3.5/site-packages/keras/callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (33.042959). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "   2/7830 [..............................] - ETA: 38:19:17 - loss: 1.8429 - acc: 0.6517"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/icecream/.local/lib/python3.5/site-packages/keras/callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (16.521904). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7830/7830 [==============================] - 9158s 1s/step - loss: 1.8465 - acc: 0.6402\n",
      "Epoch 5/20\n",
      "\n",
      "Epoch 00005: LearningRateScheduler setting learning rate to 0.00015848931924611134.\n",
      "   1/7830 [..............................] - ETA: 2:23:57 - loss: 1.7506 - acc: 0.6537"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/icecream/.local/lib/python3.5/site-packages/keras/callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (33.057683). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "   2/7830 [..............................] - ETA: 38:20:25 - loss: 1.7856 - acc: 0.6551"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/icecream/.local/lib/python3.5/site-packages/keras/callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (16.529377). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7830/7830 [==============================] - 9156s 1s/step - loss: 1.7982 - acc: 0.6477\n",
      "Epoch 6/20\n",
      "\n",
      "Epoch 00006: LearningRateScheduler setting learning rate to 0.0001.\n",
      "   1/7830 [..............................] - ETA: 2:23:30 - loss: 1.8347 - acc: 0.6498"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/icecream/.local/lib/python3.5/site-packages/keras/callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (33.061517). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "   2/7830 [..............................] - ETA: 38:21:11 - loss: 1.8439 - acc: 0.6380"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/icecream/.local/lib/python3.5/site-packages/keras/callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (16.531305). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1193/7830 [===>..........................] - ETA: 2:10:59 - loss: 1.7757 - acc: 0.6511"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-88fa0f04ca15>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mevaluate_callback_classification\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr_decay_callback\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m )\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1416\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1417\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1418\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1420\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    215\u001b[0m                 outs = model.train_on_batch(x, y,\n\u001b[1;32m    216\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m                                             class_weight=class_weight)\n\u001b[0m\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1215\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1216\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1217\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1218\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1449\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_with_new_api\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1450\u001b[0m           return tf_session.TF_SessionRunCallable(\n\u001b[0;32m-> 1451\u001b[0;31m               self._session._session, self._handle, args, status, None)\n\u001b[0m\u001b[1;32m   1452\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1453\u001b[0m           return tf_session.TF_DeprecatedSessionRunCallable(\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = classificaton_model.fit_generator(\n",
    "    classification_train_data,\n",
    "    steps_per_epoch=int(len(train_X) / (BATCH_SIZE)),\n",
    "    epochs=20,\n",
    "    verbose=1,\n",
    "    callbacks=[evaluate_callback_classification, lr_decay_callback],\n",
    "    initial_epoch=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "classificaton_model.save(\"model_256\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[65262, 137744]\n"
     ]
    }
   ],
   "source": [
    "for x in test_X:\n",
    "    indices = make_indices_from_x(x, index_by_token)\n",
    "    print(indices)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_real_labels(filename):\n",
    "    with open(filename, \"rb\") as handler:\n",
    "        real_labels = set()\n",
    "        for line in handler:\n",
    "            label = line.decode(\"utf-8\").strip().split(\"\\t\")[1]\n",
    "            real_labels.add(label)\n",
    "    return real_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_labels = get_real_labels(TRAIN_FILENAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_real_label = {\n",
    "    real_label.lower(): real_label\n",
    "    for real_label in real_labels\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import codecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = codecs.open(\"val_X\", \"w\", \"utf-8\")\n",
    "for x in val_X:        \n",
    "    file.write(x + \"\\n\")\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = codecs.open(\"val_Y\", \"w\", \"utf-8\")\n",
    "for x in val_Y:        \n",
    "    file.write(x + \"\\n\")\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = codecs.open(\"train_X\", \"w\", \"utf-8\")\n",
    "for x in train_X:        \n",
    "    file.write(x + \"\\n\")\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = codecs.open(\"train_Y\", \"w\", \"utf-8\")\n",
    "for x in train_Y:        \n",
    "    file.write(x + \"\\n\")\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_net_input(X):\n",
    "    net_input = []\n",
    "    for i, x in enumerate(X):\n",
    "        if i % 1000 == 0:\n",
    "            print(\"{} / {}\".format(i, len(X)))\n",
    "        cur_net_input = np.zeros(MAX_LEN)\n",
    "        indices = make_indices_from_x(x, index_by_token)\n",
    "        cur_net_input[:len(indices)] = indices\n",
    "        net_input.append(cur_net_input)\n",
    "    return np.array(net_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 / 1000000\n",
      "1000 / 1000000\n",
      "2000 / 1000000\n",
      "3000 / 1000000\n",
      "4000 / 1000000\n",
      "5000 / 1000000\n",
      "6000 / 1000000\n",
      "7000 / 1000000\n",
      "8000 / 1000000\n",
      "9000 / 1000000\n",
      "10000 / 1000000\n",
      "11000 / 1000000\n",
      "12000 / 1000000\n",
      "13000 / 1000000\n",
      "14000 / 1000000\n",
      "15000 / 1000000\n",
      "16000 / 1000000\n",
      "17000 / 1000000\n",
      "18000 / 1000000\n",
      "19000 / 1000000\n",
      "20000 / 1000000\n",
      "21000 / 1000000\n",
      "22000 / 1000000\n",
      "23000 / 1000000\n",
      "24000 / 1000000\n",
      "25000 / 1000000\n",
      "26000 / 1000000\n",
      "27000 / 1000000\n",
      "28000 / 1000000\n",
      "29000 / 1000000\n",
      "30000 / 1000000\n",
      "31000 / 1000000\n",
      "32000 / 1000000\n",
      "33000 / 1000000\n",
      "34000 / 1000000\n",
      "35000 / 1000000\n",
      "36000 / 1000000\n",
      "37000 / 1000000\n",
      "38000 / 1000000\n",
      "39000 / 1000000\n",
      "40000 / 1000000\n",
      "41000 / 1000000\n",
      "42000 / 1000000\n",
      "43000 / 1000000\n",
      "44000 / 1000000\n",
      "45000 / 1000000\n",
      "46000 / 1000000\n",
      "47000 / 1000000\n",
      "48000 / 1000000\n",
      "49000 / 1000000\n",
      "50000 / 1000000\n",
      "51000 / 1000000\n",
      "52000 / 1000000\n",
      "53000 / 1000000\n",
      "54000 / 1000000\n",
      "55000 / 1000000\n",
      "56000 / 1000000\n",
      "57000 / 1000000\n",
      "58000 / 1000000\n",
      "59000 / 1000000\n",
      "60000 / 1000000\n",
      "61000 / 1000000\n",
      "62000 / 1000000\n",
      "63000 / 1000000\n",
      "64000 / 1000000\n",
      "65000 / 1000000\n",
      "66000 / 1000000\n",
      "67000 / 1000000\n",
      "68000 / 1000000\n",
      "69000 / 1000000\n",
      "70000 / 1000000\n",
      "71000 / 1000000\n",
      "72000 / 1000000\n",
      "73000 / 1000000\n",
      "74000 / 1000000\n",
      "75000 / 1000000\n",
      "76000 / 1000000\n",
      "77000 / 1000000\n",
      "78000 / 1000000\n",
      "79000 / 1000000\n",
      "80000 / 1000000\n",
      "81000 / 1000000\n",
      "82000 / 1000000\n",
      "83000 / 1000000\n",
      "84000 / 1000000\n",
      "85000 / 1000000\n",
      "86000 / 1000000\n",
      "87000 / 1000000\n",
      "88000 / 1000000\n",
      "89000 / 1000000\n",
      "90000 / 1000000\n",
      "91000 / 1000000\n",
      "92000 / 1000000\n",
      "93000 / 1000000\n",
      "94000 / 1000000\n",
      "95000 / 1000000\n",
      "96000 / 1000000\n",
      "97000 / 1000000\n",
      "98000 / 1000000\n",
      "99000 / 1000000\n",
      "100000 / 1000000\n",
      "101000 / 1000000\n",
      "102000 / 1000000\n",
      "103000 / 1000000\n",
      "104000 / 1000000\n",
      "105000 / 1000000\n",
      "106000 / 1000000\n",
      "107000 / 1000000\n",
      "108000 / 1000000\n",
      "109000 / 1000000\n",
      "110000 / 1000000\n",
      "111000 / 1000000\n",
      "112000 / 1000000\n",
      "113000 / 1000000\n",
      "114000 / 1000000\n",
      "115000 / 1000000\n",
      "116000 / 1000000\n",
      "117000 / 1000000\n",
      "118000 / 1000000\n",
      "119000 / 1000000\n",
      "120000 / 1000000\n",
      "121000 / 1000000\n",
      "122000 / 1000000\n",
      "123000 / 1000000\n",
      "124000 / 1000000\n",
      "125000 / 1000000\n",
      "126000 / 1000000\n",
      "127000 / 1000000\n",
      "128000 / 1000000\n",
      "129000 / 1000000\n",
      "130000 / 1000000\n",
      "131000 / 1000000\n",
      "132000 / 1000000\n",
      "133000 / 1000000\n",
      "134000 / 1000000\n",
      "135000 / 1000000\n",
      "136000 / 1000000\n",
      "137000 / 1000000\n",
      "138000 / 1000000\n",
      "139000 / 1000000\n",
      "140000 / 1000000\n",
      "141000 / 1000000\n",
      "142000 / 1000000\n",
      "143000 / 1000000\n",
      "144000 / 1000000\n",
      "145000 / 1000000\n",
      "146000 / 1000000\n",
      "147000 / 1000000\n",
      "148000 / 1000000\n",
      "149000 / 1000000\n",
      "150000 / 1000000\n",
      "151000 / 1000000\n",
      "152000 / 1000000\n",
      "153000 / 1000000\n",
      "154000 / 1000000\n",
      "155000 / 1000000\n",
      "156000 / 1000000\n",
      "157000 / 1000000\n",
      "158000 / 1000000\n",
      "159000 / 1000000\n",
      "160000 / 1000000\n",
      "161000 / 1000000\n",
      "162000 / 1000000\n",
      "163000 / 1000000\n",
      "164000 / 1000000\n",
      "165000 / 1000000\n",
      "166000 / 1000000\n",
      "167000 / 1000000\n",
      "168000 / 1000000\n",
      "169000 / 1000000\n",
      "170000 / 1000000\n",
      "171000 / 1000000\n",
      "172000 / 1000000\n",
      "173000 / 1000000\n",
      "174000 / 1000000\n",
      "175000 / 1000000\n",
      "176000 / 1000000\n",
      "177000 / 1000000\n",
      "178000 / 1000000\n",
      "179000 / 1000000\n",
      "180000 / 1000000\n",
      "181000 / 1000000\n",
      "182000 / 1000000\n",
      "183000 / 1000000\n",
      "184000 / 1000000\n",
      "185000 / 1000000\n",
      "186000 / 1000000\n",
      "187000 / 1000000\n",
      "188000 / 1000000\n",
      "189000 / 1000000\n",
      "190000 / 1000000\n",
      "191000 / 1000000\n",
      "192000 / 1000000\n",
      "193000 / 1000000\n",
      "194000 / 1000000\n",
      "195000 / 1000000\n",
      "196000 / 1000000\n",
      "197000 / 1000000\n",
      "198000 / 1000000\n",
      "199000 / 1000000\n",
      "200000 / 1000000\n",
      "201000 / 1000000\n",
      "202000 / 1000000\n",
      "203000 / 1000000\n",
      "204000 / 1000000\n",
      "205000 / 1000000\n",
      "206000 / 1000000\n",
      "207000 / 1000000\n",
      "208000 / 1000000\n",
      "209000 / 1000000\n",
      "210000 / 1000000\n",
      "211000 / 1000000\n",
      "212000 / 1000000\n",
      "213000 / 1000000\n",
      "214000 / 1000000\n",
      "215000 / 1000000\n",
      "216000 / 1000000\n",
      "217000 / 1000000\n",
      "218000 / 1000000\n",
      "219000 / 1000000\n",
      "220000 / 1000000\n",
      "221000 / 1000000\n",
      "222000 / 1000000\n",
      "223000 / 1000000\n",
      "224000 / 1000000\n",
      "225000 / 1000000\n",
      "226000 / 1000000\n",
      "227000 / 1000000\n",
      "228000 / 1000000\n",
      "229000 / 1000000\n",
      "230000 / 1000000\n",
      "231000 / 1000000\n",
      "232000 / 1000000\n",
      "233000 / 1000000\n",
      "234000 / 1000000\n",
      "235000 / 1000000\n",
      "236000 / 1000000\n",
      "237000 / 1000000\n",
      "238000 / 1000000\n",
      "239000 / 1000000\n",
      "240000 / 1000000\n",
      "241000 / 1000000\n",
      "242000 / 1000000\n",
      "243000 / 1000000\n",
      "244000 / 1000000\n",
      "245000 / 1000000\n",
      "246000 / 1000000\n",
      "247000 / 1000000\n",
      "248000 / 1000000\n",
      "249000 / 1000000\n",
      "250000 / 1000000\n",
      "251000 / 1000000\n",
      "252000 / 1000000\n",
      "253000 / 1000000\n",
      "254000 / 1000000\n",
      "255000 / 1000000\n",
      "256000 / 1000000\n",
      "257000 / 1000000\n",
      "258000 / 1000000\n",
      "259000 / 1000000\n",
      "260000 / 1000000\n",
      "261000 / 1000000\n",
      "262000 / 1000000\n",
      "263000 / 1000000\n",
      "264000 / 1000000\n",
      "265000 / 1000000\n",
      "266000 / 1000000\n",
      "267000 / 1000000\n",
      "268000 / 1000000\n",
      "269000 / 1000000\n",
      "270000 / 1000000\n",
      "271000 / 1000000\n",
      "272000 / 1000000\n",
      "273000 / 1000000\n",
      "274000 / 1000000\n",
      "275000 / 1000000\n",
      "276000 / 1000000\n",
      "277000 / 1000000\n",
      "278000 / 1000000\n",
      "279000 / 1000000\n",
      "280000 / 1000000\n",
      "281000 / 1000000\n",
      "282000 / 1000000\n",
      "283000 / 1000000\n",
      "284000 / 1000000\n",
      "285000 / 1000000\n",
      "286000 / 1000000\n",
      "287000 / 1000000\n",
      "288000 / 1000000\n",
      "289000 / 1000000\n",
      "290000 / 1000000\n",
      "291000 / 1000000\n",
      "292000 / 1000000\n",
      "293000 / 1000000\n",
      "294000 / 1000000\n",
      "295000 / 1000000\n",
      "296000 / 1000000\n",
      "297000 / 1000000\n",
      "298000 / 1000000\n",
      "299000 / 1000000\n",
      "300000 / 1000000\n",
      "301000 / 1000000\n",
      "302000 / 1000000\n",
      "303000 / 1000000\n",
      "304000 / 1000000\n",
      "305000 / 1000000\n",
      "306000 / 1000000\n",
      "307000 / 1000000\n",
      "308000 / 1000000\n",
      "309000 / 1000000\n",
      "310000 / 1000000\n",
      "311000 / 1000000\n",
      "312000 / 1000000\n",
      "313000 / 1000000\n",
      "314000 / 1000000\n",
      "315000 / 1000000\n",
      "316000 / 1000000\n",
      "317000 / 1000000\n",
      "318000 / 1000000\n",
      "319000 / 1000000\n",
      "320000 / 1000000\n",
      "321000 / 1000000\n",
      "322000 / 1000000\n",
      "323000 / 1000000\n",
      "324000 / 1000000\n",
      "325000 / 1000000\n",
      "326000 / 1000000\n",
      "327000 / 1000000\n",
      "328000 / 1000000\n",
      "329000 / 1000000\n",
      "330000 / 1000000\n",
      "331000 / 1000000\n",
      "332000 / 1000000\n",
      "333000 / 1000000\n",
      "334000 / 1000000\n",
      "335000 / 1000000\n",
      "336000 / 1000000\n",
      "337000 / 1000000\n",
      "338000 / 1000000\n",
      "339000 / 1000000\n",
      "340000 / 1000000\n",
      "341000 / 1000000\n",
      "342000 / 1000000\n",
      "343000 / 1000000\n",
      "344000 / 1000000\n",
      "345000 / 1000000\n",
      "346000 / 1000000\n",
      "347000 / 1000000\n",
      "348000 / 1000000\n",
      "349000 / 1000000\n",
      "350000 / 1000000\n",
      "351000 / 1000000\n",
      "352000 / 1000000\n",
      "353000 / 1000000\n",
      "354000 / 1000000\n",
      "355000 / 1000000\n",
      "356000 / 1000000\n",
      "357000 / 1000000\n",
      "358000 / 1000000\n",
      "359000 / 1000000\n",
      "360000 / 1000000\n",
      "361000 / 1000000\n",
      "362000 / 1000000\n",
      "363000 / 1000000\n",
      "364000 / 1000000\n",
      "365000 / 1000000\n",
      "366000 / 1000000\n",
      "367000 / 1000000\n",
      "368000 / 1000000\n",
      "369000 / 1000000\n",
      "370000 / 1000000\n",
      "371000 / 1000000\n",
      "372000 / 1000000\n",
      "373000 / 1000000\n",
      "374000 / 1000000\n",
      "375000 / 1000000\n",
      "376000 / 1000000\n",
      "377000 / 1000000\n",
      "378000 / 1000000\n",
      "379000 / 1000000\n",
      "380000 / 1000000\n",
      "381000 / 1000000\n",
      "382000 / 1000000\n",
      "383000 / 1000000\n",
      "384000 / 1000000\n",
      "385000 / 1000000\n",
      "386000 / 1000000\n",
      "387000 / 1000000\n",
      "388000 / 1000000\n",
      "389000 / 1000000\n",
      "390000 / 1000000\n",
      "391000 / 1000000\n",
      "392000 / 1000000\n",
      "393000 / 1000000\n",
      "394000 / 1000000\n",
      "395000 / 1000000\n",
      "396000 / 1000000\n",
      "397000 / 1000000\n",
      "398000 / 1000000\n",
      "399000 / 1000000\n",
      "400000 / 1000000\n",
      "401000 / 1000000\n",
      "402000 / 1000000\n",
      "403000 / 1000000\n",
      "404000 / 1000000\n",
      "405000 / 1000000\n",
      "406000 / 1000000\n",
      "407000 / 1000000\n",
      "408000 / 1000000\n",
      "409000 / 1000000\n",
      "410000 / 1000000\n",
      "411000 / 1000000\n",
      "412000 / 1000000\n",
      "413000 / 1000000\n",
      "414000 / 1000000\n",
      "415000 / 1000000\n",
      "416000 / 1000000\n",
      "417000 / 1000000\n",
      "418000 / 1000000\n",
      "419000 / 1000000\n",
      "420000 / 1000000\n",
      "421000 / 1000000\n",
      "422000 / 1000000\n",
      "423000 / 1000000\n",
      "424000 / 1000000\n",
      "425000 / 1000000\n",
      "426000 / 1000000\n",
      "427000 / 1000000\n",
      "428000 / 1000000\n",
      "429000 / 1000000\n",
      "430000 / 1000000\n",
      "431000 / 1000000\n",
      "432000 / 1000000\n",
      "433000 / 1000000\n",
      "434000 / 1000000\n",
      "435000 / 1000000\n",
      "436000 / 1000000\n",
      "437000 / 1000000\n",
      "438000 / 1000000\n",
      "439000 / 1000000\n",
      "440000 / 1000000\n",
      "441000 / 1000000\n",
      "442000 / 1000000\n",
      "443000 / 1000000\n",
      "444000 / 1000000\n",
      "445000 / 1000000\n",
      "446000 / 1000000\n",
      "447000 / 1000000\n",
      "448000 / 1000000\n",
      "449000 / 1000000\n",
      "450000 / 1000000\n",
      "451000 / 1000000\n",
      "452000 / 1000000\n",
      "453000 / 1000000\n",
      "454000 / 1000000\n",
      "455000 / 1000000\n",
      "456000 / 1000000\n",
      "457000 / 1000000\n",
      "458000 / 1000000\n",
      "459000 / 1000000\n",
      "460000 / 1000000\n",
      "461000 / 1000000\n",
      "462000 / 1000000\n",
      "463000 / 1000000\n",
      "464000 / 1000000\n",
      "465000 / 1000000\n",
      "466000 / 1000000\n",
      "467000 / 1000000\n",
      "468000 / 1000000\n",
      "469000 / 1000000\n",
      "470000 / 1000000\n",
      "471000 / 1000000\n",
      "472000 / 1000000\n",
      "473000 / 1000000\n",
      "474000 / 1000000\n",
      "475000 / 1000000\n",
      "476000 / 1000000\n",
      "477000 / 1000000\n",
      "478000 / 1000000\n",
      "479000 / 1000000\n",
      "480000 / 1000000\n",
      "481000 / 1000000\n",
      "482000 / 1000000\n",
      "483000 / 1000000\n",
      "484000 / 1000000\n",
      "485000 / 1000000\n",
      "486000 / 1000000\n",
      "487000 / 1000000\n",
      "488000 / 1000000\n",
      "489000 / 1000000\n",
      "490000 / 1000000\n",
      "491000 / 1000000\n",
      "492000 / 1000000\n",
      "493000 / 1000000\n",
      "494000 / 1000000\n",
      "495000 / 1000000\n",
      "496000 / 1000000\n",
      "497000 / 1000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "498000 / 1000000\n",
      "499000 / 1000000\n",
      "500000 / 1000000\n",
      "501000 / 1000000\n",
      "502000 / 1000000\n",
      "503000 / 1000000\n",
      "504000 / 1000000\n",
      "505000 / 1000000\n",
      "506000 / 1000000\n",
      "507000 / 1000000\n",
      "508000 / 1000000\n",
      "509000 / 1000000\n",
      "510000 / 1000000\n",
      "511000 / 1000000\n",
      "512000 / 1000000\n",
      "513000 / 1000000\n",
      "514000 / 1000000\n",
      "515000 / 1000000\n",
      "516000 / 1000000\n",
      "517000 / 1000000\n",
      "518000 / 1000000\n",
      "519000 / 1000000\n",
      "520000 / 1000000\n",
      "521000 / 1000000\n",
      "522000 / 1000000\n",
      "523000 / 1000000\n",
      "524000 / 1000000\n",
      "525000 / 1000000\n",
      "526000 / 1000000\n",
      "527000 / 1000000\n",
      "528000 / 1000000\n",
      "529000 / 1000000\n",
      "530000 / 1000000\n",
      "531000 / 1000000\n",
      "532000 / 1000000\n",
      "533000 / 1000000\n",
      "534000 / 1000000\n",
      "535000 / 1000000\n",
      "536000 / 1000000\n",
      "537000 / 1000000\n",
      "538000 / 1000000\n",
      "539000 / 1000000\n",
      "540000 / 1000000\n",
      "541000 / 1000000\n",
      "542000 / 1000000\n",
      "543000 / 1000000\n",
      "544000 / 1000000\n",
      "545000 / 1000000\n",
      "546000 / 1000000\n",
      "547000 / 1000000\n",
      "548000 / 1000000\n",
      "549000 / 1000000\n",
      "550000 / 1000000\n",
      "551000 / 1000000\n",
      "552000 / 1000000\n",
      "553000 / 1000000\n",
      "554000 / 1000000\n",
      "555000 / 1000000\n",
      "556000 / 1000000\n",
      "557000 / 1000000\n",
      "558000 / 1000000\n",
      "559000 / 1000000\n",
      "560000 / 1000000\n",
      "561000 / 1000000\n",
      "562000 / 1000000\n",
      "563000 / 1000000\n",
      "564000 / 1000000\n",
      "565000 / 1000000\n",
      "566000 / 1000000\n",
      "567000 / 1000000\n",
      "568000 / 1000000\n",
      "569000 / 1000000\n",
      "570000 / 1000000\n",
      "571000 / 1000000\n",
      "572000 / 1000000\n",
      "573000 / 1000000\n",
      "574000 / 1000000\n",
      "575000 / 1000000\n",
      "576000 / 1000000\n",
      "577000 / 1000000\n",
      "578000 / 1000000\n",
      "579000 / 1000000\n",
      "580000 / 1000000\n",
      "581000 / 1000000\n",
      "582000 / 1000000\n",
      "583000 / 1000000\n",
      "584000 / 1000000\n",
      "585000 / 1000000\n",
      "586000 / 1000000\n",
      "587000 / 1000000\n",
      "588000 / 1000000\n",
      "589000 / 1000000\n",
      "590000 / 1000000\n",
      "591000 / 1000000\n",
      "592000 / 1000000\n",
      "593000 / 1000000\n",
      "594000 / 1000000\n",
      "595000 / 1000000\n",
      "596000 / 1000000\n",
      "597000 / 1000000\n",
      "598000 / 1000000\n",
      "599000 / 1000000\n",
      "600000 / 1000000\n",
      "601000 / 1000000\n",
      "602000 / 1000000\n",
      "603000 / 1000000\n",
      "604000 / 1000000\n",
      "605000 / 1000000\n",
      "606000 / 1000000\n",
      "607000 / 1000000\n",
      "608000 / 1000000\n",
      "609000 / 1000000\n",
      "610000 / 1000000\n",
      "611000 / 1000000\n",
      "612000 / 1000000\n",
      "613000 / 1000000\n",
      "614000 / 1000000\n",
      "615000 / 1000000\n",
      "616000 / 1000000\n",
      "617000 / 1000000\n",
      "618000 / 1000000\n",
      "619000 / 1000000\n",
      "620000 / 1000000\n",
      "621000 / 1000000\n",
      "622000 / 1000000\n",
      "623000 / 1000000\n",
      "624000 / 1000000\n",
      "625000 / 1000000\n",
      "626000 / 1000000\n",
      "627000 / 1000000\n",
      "628000 / 1000000\n",
      "629000 / 1000000\n",
      "630000 / 1000000\n",
      "631000 / 1000000\n",
      "632000 / 1000000\n",
      "633000 / 1000000\n",
      "634000 / 1000000\n",
      "635000 / 1000000\n",
      "636000 / 1000000\n",
      "637000 / 1000000\n",
      "638000 / 1000000\n",
      "639000 / 1000000\n",
      "640000 / 1000000\n",
      "641000 / 1000000\n",
      "642000 / 1000000\n",
      "643000 / 1000000\n",
      "644000 / 1000000\n",
      "645000 / 1000000\n",
      "646000 / 1000000\n",
      "647000 / 1000000\n",
      "648000 / 1000000\n",
      "649000 / 1000000\n",
      "650000 / 1000000\n",
      "651000 / 1000000\n",
      "652000 / 1000000\n",
      "653000 / 1000000\n",
      "654000 / 1000000\n",
      "655000 / 1000000\n",
      "656000 / 1000000\n",
      "657000 / 1000000\n",
      "658000 / 1000000\n",
      "659000 / 1000000\n",
      "660000 / 1000000\n",
      "661000 / 1000000\n",
      "662000 / 1000000\n",
      "663000 / 1000000\n",
      "664000 / 1000000\n",
      "665000 / 1000000\n",
      "666000 / 1000000\n",
      "667000 / 1000000\n",
      "668000 / 1000000\n",
      "669000 / 1000000\n",
      "670000 / 1000000\n",
      "671000 / 1000000\n",
      "672000 / 1000000\n",
      "673000 / 1000000\n",
      "674000 / 1000000\n",
      "675000 / 1000000\n",
      "676000 / 1000000\n",
      "677000 / 1000000\n",
      "678000 / 1000000\n",
      "679000 / 1000000\n",
      "680000 / 1000000\n",
      "681000 / 1000000\n",
      "682000 / 1000000\n",
      "683000 / 1000000\n",
      "684000 / 1000000\n",
      "685000 / 1000000\n",
      "686000 / 1000000\n",
      "687000 / 1000000\n",
      "688000 / 1000000\n",
      "689000 / 1000000\n",
      "690000 / 1000000\n",
      "691000 / 1000000\n",
      "692000 / 1000000\n",
      "693000 / 1000000\n",
      "694000 / 1000000\n",
      "695000 / 1000000\n",
      "696000 / 1000000\n",
      "697000 / 1000000\n",
      "698000 / 1000000\n",
      "699000 / 1000000\n",
      "700000 / 1000000\n",
      "701000 / 1000000\n",
      "702000 / 1000000\n",
      "703000 / 1000000\n",
      "704000 / 1000000\n",
      "705000 / 1000000\n",
      "706000 / 1000000\n",
      "707000 / 1000000\n",
      "708000 / 1000000\n",
      "709000 / 1000000\n",
      "710000 / 1000000\n",
      "711000 / 1000000\n",
      "712000 / 1000000\n",
      "713000 / 1000000\n",
      "714000 / 1000000\n",
      "715000 / 1000000\n",
      "716000 / 1000000\n",
      "717000 / 1000000\n",
      "718000 / 1000000\n",
      "719000 / 1000000\n",
      "720000 / 1000000\n",
      "721000 / 1000000\n",
      "722000 / 1000000\n",
      "723000 / 1000000\n",
      "724000 / 1000000\n",
      "725000 / 1000000\n",
      "726000 / 1000000\n",
      "727000 / 1000000\n",
      "728000 / 1000000\n",
      "729000 / 1000000\n",
      "730000 / 1000000\n",
      "731000 / 1000000\n",
      "732000 / 1000000\n",
      "733000 / 1000000\n",
      "734000 / 1000000\n",
      "735000 / 1000000\n",
      "736000 / 1000000\n",
      "737000 / 1000000\n",
      "738000 / 1000000\n",
      "739000 / 1000000\n",
      "740000 / 1000000\n",
      "741000 / 1000000\n",
      "742000 / 1000000\n",
      "743000 / 1000000\n",
      "744000 / 1000000\n",
      "745000 / 1000000\n",
      "746000 / 1000000\n",
      "747000 / 1000000\n",
      "748000 / 1000000\n",
      "749000 / 1000000\n",
      "750000 / 1000000\n",
      "751000 / 1000000\n",
      "752000 / 1000000\n",
      "753000 / 1000000\n",
      "754000 / 1000000\n",
      "755000 / 1000000\n",
      "756000 / 1000000\n",
      "757000 / 1000000\n",
      "758000 / 1000000\n",
      "759000 / 1000000\n",
      "760000 / 1000000\n",
      "761000 / 1000000\n",
      "762000 / 1000000\n",
      "763000 / 1000000\n",
      "764000 / 1000000\n",
      "765000 / 1000000\n",
      "766000 / 1000000\n",
      "767000 / 1000000\n",
      "768000 / 1000000\n",
      "769000 / 1000000\n",
      "770000 / 1000000\n",
      "771000 / 1000000\n",
      "772000 / 1000000\n",
      "773000 / 1000000\n",
      "774000 / 1000000\n",
      "775000 / 1000000\n",
      "776000 / 1000000\n",
      "777000 / 1000000\n",
      "778000 / 1000000\n",
      "779000 / 1000000\n",
      "780000 / 1000000\n",
      "781000 / 1000000\n",
      "782000 / 1000000\n",
      "783000 / 1000000\n",
      "784000 / 1000000\n",
      "785000 / 1000000\n",
      "786000 / 1000000\n",
      "787000 / 1000000\n",
      "788000 / 1000000\n",
      "789000 / 1000000\n",
      "790000 / 1000000\n",
      "791000 / 1000000\n",
      "792000 / 1000000\n",
      "793000 / 1000000\n",
      "794000 / 1000000\n",
      "795000 / 1000000\n",
      "796000 / 1000000\n",
      "797000 / 1000000\n",
      "798000 / 1000000\n",
      "799000 / 1000000\n",
      "800000 / 1000000\n",
      "801000 / 1000000\n",
      "802000 / 1000000\n",
      "803000 / 1000000\n",
      "804000 / 1000000\n",
      "805000 / 1000000\n",
      "806000 / 1000000\n",
      "807000 / 1000000\n",
      "808000 / 1000000\n",
      "809000 / 1000000\n",
      "810000 / 1000000\n",
      "811000 / 1000000\n",
      "812000 / 1000000\n",
      "813000 / 1000000\n",
      "814000 / 1000000\n",
      "815000 / 1000000\n",
      "816000 / 1000000\n",
      "817000 / 1000000\n",
      "818000 / 1000000\n",
      "819000 / 1000000\n",
      "820000 / 1000000\n",
      "821000 / 1000000\n",
      "822000 / 1000000\n",
      "823000 / 1000000\n",
      "824000 / 1000000\n",
      "825000 / 1000000\n",
      "826000 / 1000000\n",
      "827000 / 1000000\n",
      "828000 / 1000000\n",
      "829000 / 1000000\n",
      "830000 / 1000000\n",
      "831000 / 1000000\n",
      "832000 / 1000000\n",
      "833000 / 1000000\n",
      "834000 / 1000000\n",
      "835000 / 1000000\n",
      "836000 / 1000000\n",
      "837000 / 1000000\n",
      "838000 / 1000000\n",
      "839000 / 1000000\n",
      "840000 / 1000000\n",
      "841000 / 1000000\n",
      "842000 / 1000000\n",
      "843000 / 1000000\n",
      "844000 / 1000000\n",
      "845000 / 1000000\n",
      "846000 / 1000000\n",
      "847000 / 1000000\n",
      "848000 / 1000000\n",
      "849000 / 1000000\n",
      "850000 / 1000000\n",
      "851000 / 1000000\n",
      "852000 / 1000000\n",
      "853000 / 1000000\n",
      "854000 / 1000000\n",
      "855000 / 1000000\n",
      "856000 / 1000000\n",
      "857000 / 1000000\n",
      "858000 / 1000000\n",
      "859000 / 1000000\n",
      "860000 / 1000000\n",
      "861000 / 1000000\n",
      "862000 / 1000000\n",
      "863000 / 1000000\n",
      "864000 / 1000000\n",
      "865000 / 1000000\n",
      "866000 / 1000000\n",
      "867000 / 1000000\n",
      "868000 / 1000000\n",
      "869000 / 1000000\n",
      "870000 / 1000000\n",
      "871000 / 1000000\n",
      "872000 / 1000000\n",
      "873000 / 1000000\n",
      "874000 / 1000000\n",
      "875000 / 1000000\n",
      "876000 / 1000000\n",
      "877000 / 1000000\n",
      "878000 / 1000000\n",
      "879000 / 1000000\n",
      "880000 / 1000000\n",
      "881000 / 1000000\n",
      "882000 / 1000000\n",
      "883000 / 1000000\n",
      "884000 / 1000000\n",
      "885000 / 1000000\n",
      "886000 / 1000000\n",
      "887000 / 1000000\n",
      "888000 / 1000000\n",
      "889000 / 1000000\n",
      "890000 / 1000000\n",
      "891000 / 1000000\n",
      "892000 / 1000000\n",
      "893000 / 1000000\n",
      "894000 / 1000000\n",
      "895000 / 1000000\n",
      "896000 / 1000000\n",
      "897000 / 1000000\n",
      "898000 / 1000000\n",
      "899000 / 1000000\n",
      "900000 / 1000000\n",
      "901000 / 1000000\n",
      "902000 / 1000000\n",
      "903000 / 1000000\n",
      "904000 / 1000000\n",
      "905000 / 1000000\n",
      "906000 / 1000000\n",
      "907000 / 1000000\n",
      "908000 / 1000000\n",
      "909000 / 1000000\n",
      "910000 / 1000000\n",
      "911000 / 1000000\n",
      "912000 / 1000000\n",
      "913000 / 1000000\n",
      "914000 / 1000000\n",
      "915000 / 1000000\n",
      "916000 / 1000000\n",
      "917000 / 1000000\n",
      "918000 / 1000000\n",
      "919000 / 1000000\n",
      "920000 / 1000000\n",
      "921000 / 1000000\n",
      "922000 / 1000000\n",
      "923000 / 1000000\n",
      "924000 / 1000000\n",
      "925000 / 1000000\n",
      "926000 / 1000000\n",
      "927000 / 1000000\n",
      "928000 / 1000000\n",
      "929000 / 1000000\n",
      "930000 / 1000000\n",
      "931000 / 1000000\n",
      "932000 / 1000000\n",
      "933000 / 1000000\n",
      "934000 / 1000000\n",
      "935000 / 1000000\n",
      "936000 / 1000000\n",
      "937000 / 1000000\n",
      "938000 / 1000000\n",
      "939000 / 1000000\n",
      "940000 / 1000000\n",
      "941000 / 1000000\n",
      "942000 / 1000000\n",
      "943000 / 1000000\n",
      "944000 / 1000000\n",
      "945000 / 1000000\n",
      "946000 / 1000000\n",
      "947000 / 1000000\n",
      "948000 / 1000000\n",
      "949000 / 1000000\n",
      "950000 / 1000000\n",
      "951000 / 1000000\n",
      "952000 / 1000000\n",
      "953000 / 1000000\n",
      "954000 / 1000000\n",
      "955000 / 1000000\n",
      "956000 / 1000000\n",
      "957000 / 1000000\n",
      "958000 / 1000000\n",
      "959000 / 1000000\n",
      "960000 / 1000000\n",
      "961000 / 1000000\n",
      "962000 / 1000000\n",
      "963000 / 1000000\n",
      "964000 / 1000000\n",
      "965000 / 1000000\n",
      "966000 / 1000000\n",
      "967000 / 1000000\n",
      "968000 / 1000000\n",
      "969000 / 1000000\n",
      "970000 / 1000000\n",
      "971000 / 1000000\n",
      "972000 / 1000000\n",
      "973000 / 1000000\n",
      "974000 / 1000000\n",
      "975000 / 1000000\n",
      "976000 / 1000000\n",
      "977000 / 1000000\n",
      "978000 / 1000000\n",
      "979000 / 1000000\n",
      "980000 / 1000000\n",
      "981000 / 1000000\n",
      "982000 / 1000000\n",
      "983000 / 1000000\n",
      "984000 / 1000000\n",
      "985000 / 1000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "986000 / 1000000\n",
      "987000 / 1000000\n",
      "988000 / 1000000\n",
      "989000 / 1000000\n",
      "990000 / 1000000\n",
      "991000 / 1000000\n",
      "992000 / 1000000\n",
      "993000 / 1000000\n",
      "994000 / 1000000\n",
      "995000 / 1000000\n",
      "996000 / 1000000\n",
      "997000 / 1000000\n",
      "998000 / 1000000\n",
      "999000 / 1000000\n"
     ]
    }
   ],
   "source": [
    "test_net_input = make_net_input(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_prediction = classificaton_model.predict(test_net_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000000, 1222)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_prediction.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000000, 1222)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_prediction.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_y_by_label = {\n",
    "    label_by_y[y]: get_real_label[y]\n",
    "    for y in label_by_y\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = codecs.open(\"test_prediction\", \"w\", \"utf-8\")\n",
    "for prediction in test_prediction:\n",
    "    file.write(real_y_by_label[np.argmax(prediction)] + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"net_data\", prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: ', , ',\n",
       " 1: ' ',\n",
       " 2: ' ',\n",
       " 3: ' ',\n",
       " 4: '  ',\n",
       " 5: ' ',\n",
       " 6: ' ',\n",
       " 7: ' ',\n",
       " 8: ', ',\n",
       " 9: '   ',\n",
       " 10: ' ',\n",
       " 11: ' ',\n",
       " 12: ' ',\n",
       " 13: '  ',\n",
       " 14: '   ',\n",
       " 15: '  ',\n",
       " 16: ' ',\n",
       " 17: ' ',\n",
       " 18: '',\n",
       " 19: ' ',\n",
       " 20: '  ',\n",
       " 21: ' ',\n",
       " 22: '  ',\n",
       " 23: ' ',\n",
       " 24: '',\n",
       " 25: ' ',\n",
       " 26: '   ',\n",
       " 27: ' ',\n",
       " 28: '',\n",
       " 29: '-',\n",
       " 30: ' ',\n",
       " 31: ', , ',\n",
       " 32: '3D-',\n",
       " 33: ' ',\n",
       " 34: ' ',\n",
       " 35: '   ',\n",
       " 36: '   ',\n",
       " 37: ' ',\n",
       " 38: '  ',\n",
       " 39: '   ',\n",
       " 40: '',\n",
       " 41: '  ',\n",
       " 42: '',\n",
       " 43: ', ',\n",
       " 44: ' ',\n",
       " 45: '-',\n",
       " 46: ', ',\n",
       " 47: '- ',\n",
       " 48: '  ',\n",
       " 49: '-',\n",
       " 50: '  ',\n",
       " 51: ' ',\n",
       " 52: ' ',\n",
       " 53: '',\n",
       " 54: ' -',\n",
       " 55: '',\n",
       " 56: '   ',\n",
       " 57: '   ',\n",
       " 58: '  ',\n",
       " 59: ', , ',\n",
       " 60: ' ',\n",
       " 61: ' ',\n",
       " 62: ' ',\n",
       " 63: ' ',\n",
       " 64: '   ',\n",
       " 65: '',\n",
       " 66: '',\n",
       " 67: '-',\n",
       " 68: '  ',\n",
       " 69: ',  ',\n",
       " 70: ' ',\n",
       " 71: ' ',\n",
       " 72: ' ',\n",
       " 73: ' ',\n",
       " 74: '',\n",
       " 75: ' ',\n",
       " 76: ' ',\n",
       " 77: '-',\n",
       " 78: ' ',\n",
       " 79: ' ',\n",
       " 80: ', , ',\n",
       " 81: '-  ',\n",
       " 82: ' ',\n",
       " 83: ',  ',\n",
       " 84: '   ',\n",
       " 85: ' ',\n",
       " 86: ' ',\n",
       " 87: '',\n",
       " 88: '- ',\n",
       " 89: ' ',\n",
       " 90: '  ',\n",
       " 91: '  ',\n",
       " 92: '  ',\n",
       " 93: ' ',\n",
       " 94: '    ',\n",
       " 95: ' ',\n",
       " 96: '',\n",
       " 97: ' ',\n",
       " 98: ' ',\n",
       " 99: ' ',\n",
       " 100: '   ',\n",
       " 101: '   ',\n",
       " 102: '    ',\n",
       " 103: ' ',\n",
       " 104: '  ',\n",
       " 105: ' ',\n",
       " 106: ' ',\n",
       " 107: ' ',\n",
       " 108: '   ',\n",
       " 109: '   ',\n",
       " 110: '',\n",
       " 111: ' ',\n",
       " 112: '   ',\n",
       " 113: ' ',\n",
       " 114: ' ',\n",
       " 115: '',\n",
       " 116: ' ',\n",
       " 117: '',\n",
       " 118: '',\n",
       " 119: '',\n",
       " 120: '',\n",
       " 121: '-',\n",
       " 122: ' ',\n",
       " 123: ' ',\n",
       " 124: '  ',\n",
       " 125: ' ',\n",
       " 126: ' ,  ',\n",
       " 127: '',\n",
       " 128: '',\n",
       " 129: ' ',\n",
       " 130: '   ',\n",
       " 131: '',\n",
       " 132: ' ',\n",
       " 133: '  ',\n",
       " 134: ' ',\n",
       " 135: '',\n",
       " 136: ' ',\n",
       " 137: '',\n",
       " 138: ', , ',\n",
       " 139: ' ',\n",
       " 140: '  ',\n",
       " 141: '  ',\n",
       " 142: '  ',\n",
       " 143: ' ',\n",
       " 144: '  ',\n",
       " 145: ' ',\n",
       " 146: ' ',\n",
       " 147: '',\n",
       " 148: '   ',\n",
       " 149: '  ',\n",
       " 150: '',\n",
       " 151: '',\n",
       " 152: ' ',\n",
       " 153: ' ',\n",
       " 154: ' ',\n",
       " 155: '- ',\n",
       " 156: ',  ',\n",
       " 157: ' ',\n",
       " 158: '',\n",
       " 159: ' ',\n",
       " 160: '   ',\n",
       " 161: '   ',\n",
       " 162: '   ',\n",
       " 163: '    ',\n",
       " 164: ', ',\n",
       " 165: '  ',\n",
       " 166: ' ',\n",
       " 167: '   ',\n",
       " 168: '- ',\n",
       " 169: '',\n",
       " 170: ' ',\n",
       " 171: '',\n",
       " 172: ' ',\n",
       " 173: '  ',\n",
       " 174: '',\n",
       " 175: '',\n",
       " 176: '    ',\n",
       " 177: ' ',\n",
       " 178: ', ',\n",
       " 179: ' ',\n",
       " 180: '  ',\n",
       " 181: '   ',\n",
       " 182: ' ',\n",
       " 183: ' ',\n",
       " 184: ' ',\n",
       " 185: '',\n",
       " 186: ' ',\n",
       " 187: '   ',\n",
       " 188: '   ',\n",
       " 189: '  ',\n",
       " 190: '',\n",
       " 191: ' ',\n",
       " 192: '',\n",
       " 193: ' ',\n",
       " 194: ' ',\n",
       " 195: '',\n",
       " 196: ' ',\n",
       " 197: '',\n",
       " 198: ' ',\n",
       " 199: '',\n",
       " 200: ' ',\n",
       " 201: 'GPS-',\n",
       " 202: ' ',\n",
       " 203: '  ',\n",
       " 204: ' ',\n",
       " 205: ' ',\n",
       " 206: ' ',\n",
       " 207: '',\n",
       " 208: '',\n",
       " 209: ' ',\n",
       " 210: '  ',\n",
       " 211: '',\n",
       " 212: '-',\n",
       " 213: '  ',\n",
       " 214: '',\n",
       " 215: ' ',\n",
       " 216: '  ',\n",
       " 217: ' ',\n",
       " 218: ',  ',\n",
       " 219: '',\n",
       " 220: '',\n",
       " 221: ' ',\n",
       " 222: '    ',\n",
       " 223: ' ',\n",
       " 224: '',\n",
       " 225: '',\n",
       " 226: '',\n",
       " 227: ' ',\n",
       " 228: '   ',\n",
       " 229: '   ',\n",
       " 230: ' ',\n",
       " 231: '   ',\n",
       " 232: 'IP-',\n",
       " 233: '',\n",
       " 234: '',\n",
       " 235: ' ',\n",
       " 236: '  ',\n",
       " 237: ' ',\n",
       " 238: '  ',\n",
       " 239: '   ',\n",
       " 240: '',\n",
       " 241: ',  ',\n",
       " 242: '   ',\n",
       " 243: '    ',\n",
       " 244: '',\n",
       " 245: '  ',\n",
       " 246: '   ',\n",
       " 247: '   ',\n",
       " 248: ' ',\n",
       " 249: ' , , ',\n",
       " 250: ' ',\n",
       " 251: '  ',\n",
       " 252: ' ',\n",
       " 253: '   ',\n",
       " 254: '',\n",
       " 255: ' ',\n",
       " 256: '    ',\n",
       " 257: ' ',\n",
       " 258: '  ',\n",
       " 259: '',\n",
       " 260: ' ',\n",
       " 261: '',\n",
       " 262: ' ',\n",
       " 263: ' ',\n",
       " 264: '',\n",
       " 265: ' ',\n",
       " 266: ' ',\n",
       " 267: '',\n",
       " 268: ' ',\n",
       " 269: '   ',\n",
       " 270: '  ',\n",
       " 271: '',\n",
       " 272: '',\n",
       " 273: '',\n",
       " 274: '  ',\n",
       " 275: '   ',\n",
       " 276: '',\n",
       " 277: ' ',\n",
       " 278: '    ',\n",
       " 279: ' ',\n",
       " 280: ' ',\n",
       " 281: ' ',\n",
       " 282: '   ',\n",
       " 283: ' ',\n",
       " 284: '',\n",
       " 285: ' ',\n",
       " 286: '',\n",
       " 287: ' ',\n",
       " 288: ' , ',\n",
       " 289: '   ',\n",
       " 290: '',\n",
       " 291: '',\n",
       " 292: ' ',\n",
       " 293: ' ',\n",
       " 294: ' ',\n",
       " 295: '',\n",
       " 296: ',  ',\n",
       " 297: ' ',\n",
       " 298: '',\n",
       " 299: ' ',\n",
       " 300: '',\n",
       " 301: ' ',\n",
       " 302: '',\n",
       " 303: '   ',\n",
       " 304: '   ',\n",
       " 305: ' ',\n",
       " 306: ' ',\n",
       " 307: ' ',\n",
       " 308: '- ',\n",
       " 309: ' ',\n",
       " 310: ' ',\n",
       " 311: '   ',\n",
       " 312: '',\n",
       " 313: ' ',\n",
       " 314: '',\n",
       " 315: ' ',\n",
       " 316: '',\n",
       " 317: '   ',\n",
       " 318: ' ',\n",
       " 319: ' ',\n",
       " 320: ' ',\n",
       " 321: ' ',\n",
       " 322: ' ',\n",
       " 323: '',\n",
       " 324: ' ',\n",
       " 325: '-',\n",
       " 326: ' ',\n",
       " 327: ' ',\n",
       " 328: '   ',\n",
       " 329: ', ',\n",
       " 330: '   ',\n",
       " 331: '   ',\n",
       " 332: ', ',\n",
       " 333: '- ',\n",
       " 334: ' ',\n",
       " 335: '-',\n",
       " 336: ' ',\n",
       " 337: ' ',\n",
       " 338: '      ',\n",
       " 339: '  ',\n",
       " 340: '   ',\n",
       " 341: '   ',\n",
       " 342: '',\n",
       " 343: ' ',\n",
       " 344: ' ',\n",
       " 345: ' ',\n",
       " 346: ' ',\n",
       " 347: ' ',\n",
       " 348: '',\n",
       " 349: '',\n",
       " 350: ' , ',\n",
       " 351: ' ',\n",
       " 352: ' ',\n",
       " 353: ' ',\n",
       " 354: '',\n",
       " 355: ' ',\n",
       " 356: '  ',\n",
       " 357: '    ',\n",
       " 358: ' ',\n",
       " 359: '  ',\n",
       " 360: ' ',\n",
       " 361: ' ',\n",
       " 362: '  ',\n",
       " 363: '  ',\n",
       " 364: ', ',\n",
       " 365: '',\n",
       " 366: ' ',\n",
       " 367: '    ',\n",
       " 368: ' ',\n",
       " 369: ' ',\n",
       " 370: ' ',\n",
       " 371: '-',\n",
       " 372: '  ',\n",
       " 373: '   ',\n",
       " 374: ' ',\n",
       " 375: '',\n",
       " 376: '   ',\n",
       " 377: '',\n",
       " 378: ' ',\n",
       " 379: 'IT-',\n",
       " 380: '',\n",
       " 381: ' ',\n",
       " 382: ' ',\n",
       " 383: '',\n",
       " 384: '  ',\n",
       " 385: '  ',\n",
       " 386: '  ',\n",
       " 387: '',\n",
       " 388: ' ',\n",
       " 389: '',\n",
       " 390: '',\n",
       " 391: '  ',\n",
       " 392: ' ',\n",
       " 393: ' ',\n",
       " 394: '',\n",
       " 395: ' ',\n",
       " 396: ' ',\n",
       " 397: '  ',\n",
       " 398: '  ',\n",
       " 399: '   ',\n",
       " 400: '  ',\n",
       " 401: '',\n",
       " 402: ' ',\n",
       " 403: ' ',\n",
       " 404: ' ',\n",
       " 405: ' ',\n",
       " 406: '    ',\n",
       " 407: '  ',\n",
       " 408: ' ',\n",
       " 409: ' ',\n",
       " 410: ' ',\n",
       " 411: ' ',\n",
       " 412: ' ',\n",
       " 413: ' ,  ',\n",
       " 414: ' ',\n",
       " 415: '-',\n",
       " 416: ' , ',\n",
       " 417: ' ',\n",
       " 418: '  ',\n",
       " 419: ' ',\n",
       " 420: '',\n",
       " 421: '   ',\n",
       " 422: '  ',\n",
       " 423: ' ',\n",
       " 424: '',\n",
       " 425: ' ',\n",
       " 426: '   ',\n",
       " 427: '',\n",
       " 428: ' ',\n",
       " 429: '  ',\n",
       " 430: '- ',\n",
       " 431: '',\n",
       " 432: '  ',\n",
       " 433: ' ',\n",
       " 434: ' ',\n",
       " 435: ' ',\n",
       " 436: ' ',\n",
       " 437: ', ',\n",
       " 438: ' ',\n",
       " 439: '  ',\n",
       " 440: ' ',\n",
       " 441: ' ',\n",
       " 442: '',\n",
       " 443: '  ',\n",
       " 444: ' ',\n",
       " 445: '',\n",
       " 446: ' ',\n",
       " 447: '-',\n",
       " 448: ' ',\n",
       " 449: '    ',\n",
       " 450: '  ',\n",
       " 451: '    ',\n",
       " 452: ' ',\n",
       " 453: ' ',\n",
       " 454: '',\n",
       " 455: ' ',\n",
       " 456: ' ',\n",
       " 457: '   ',\n",
       " 458: '',\n",
       " 459: '',\n",
       " 460: ' ',\n",
       " 461: ', ',\n",
       " 462: '   , ',\n",
       " 463: '',\n",
       " 464: '',\n",
       " 465: '',\n",
       " 466: ' ',\n",
       " 467: '  ',\n",
       " 468: ' ',\n",
       " 469: ', , ',\n",
       " 470: '',\n",
       " 471: '  ',\n",
       " 472: ' ',\n",
       " 473: ' ',\n",
       " 474: '',\n",
       " 475: '  ',\n",
       " 476: '',\n",
       " 477: '   ',\n",
       " 478: ', ',\n",
       " 479: '-',\n",
       " 480: ' ',\n",
       " 481: ' ',\n",
       " 482: ' ',\n",
       " 483: ',    ',\n",
       " 484: '',\n",
       " 485: ' ',\n",
       " 486: '   ',\n",
       " 487: ' ',\n",
       " 488: '-',\n",
       " 489: '',\n",
       " 490: '  ',\n",
       " 491: '',\n",
       " 492: ' ',\n",
       " 493: '  ',\n",
       " 494: '- ',\n",
       " 495: ' ',\n",
       " 496: ' ',\n",
       " 497: ' ',\n",
       " 498: ' ',\n",
       " 499: ', ',\n",
       " 500: '   ',\n",
       " 501: ' ',\n",
       " 502: ' ',\n",
       " 503: '    ',\n",
       " 504: '  ',\n",
       " 505: '  ',\n",
       " 506: '',\n",
       " 507: '-',\n",
       " 508: '',\n",
       " 509: ' ',\n",
       " 510: ' ',\n",
       " 511: ' ',\n",
       " 512: ' ',\n",
       " 513: '   ',\n",
       " 514: ' ',\n",
       " 515: '- ',\n",
       " 516: ' ',\n",
       " 517: ' ',\n",
       " 518: '  ',\n",
       " 519: ', ,  ',\n",
       " 520: '     ',\n",
       " 521: '  ',\n",
       " 522: ',  ',\n",
       " 523: '',\n",
       " 524: ', , ',\n",
       " 525: ' ',\n",
       " 526: ' ',\n",
       " 527: ' ',\n",
       " 528: '  ',\n",
       " 529: '   ',\n",
       " 530: ' ',\n",
       " 531: '',\n",
       " 532: '    ',\n",
       " 533: '   ',\n",
       " 534: '- ',\n",
       " 535: '   ',\n",
       " 536: '  ',\n",
       " 537: '',\n",
       " 538: ' ',\n",
       " 539: ' ',\n",
       " 540: ' ',\n",
       " 541: '   ',\n",
       " 542: ' ',\n",
       " 543: ' ',\n",
       " 544: ' ',\n",
       " 545: ' ',\n",
       " 546: ' ',\n",
       " 547: '    ',\n",
       " 548: ' ',\n",
       " 549: '',\n",
       " 550: '   ',\n",
       " 551: ' ',\n",
       " 552: ' ',\n",
       " 553: ', ',\n",
       " 554: '    ',\n",
       " 555: ' ',\n",
       " 556: '  ',\n",
       " 557: ' ',\n",
       " 558: ' ',\n",
       " 559: '',\n",
       " 560: ' ',\n",
       " 561: ' ',\n",
       " 562: ' ',\n",
       " 563: '   ',\n",
       " 564: ' ',\n",
       " 565: ' ',\n",
       " 566: '  ',\n",
       " 567: ',  ',\n",
       " 568: ' ',\n",
       " 569: ', ',\n",
       " 570: '-',\n",
       " 571: '',\n",
       " 572: '   ',\n",
       " 573: '  ',\n",
       " 574: '  ',\n",
       " 575: ' ',\n",
       " 576: ' ',\n",
       " 577: '- ',\n",
       " 578: '   ',\n",
       " 579: '  ',\n",
       " 580: '',\n",
       " 581: ' ',\n",
       " 582: ' ',\n",
       " 583: '',\n",
       " 584: ' ',\n",
       " 585: '',\n",
       " 586: ' ',\n",
       " 587: ', ',\n",
       " 588: '  ',\n",
       " 589: '  ',\n",
       " 590: ' ',\n",
       " 591: '  ',\n",
       " 592: ' ',\n",
       " 593: '',\n",
       " 594: '    ',\n",
       " 595: ' ',\n",
       " 596: '   ',\n",
       " 597: ' ',\n",
       " 598: '   ',\n",
       " 599: '   ',\n",
       " 600: '  ',\n",
       " 601: '-',\n",
       " 602: ' ',\n",
       " 603: '-',\n",
       " 604: ' ',\n",
       " 605: '',\n",
       " 606: '   ',\n",
       " 607: ' ',\n",
       " 608: '   ',\n",
       " 609: '   ',\n",
       " 610: '',\n",
       " 611: '',\n",
       " 612: ',  ,   ',\n",
       " 613: '',\n",
       " 614: ' ',\n",
       " 615: '   ',\n",
       " 616: ' ',\n",
       " 617: ' ',\n",
       " 618: '   ',\n",
       " 619: ' ',\n",
       " 620: '  ',\n",
       " 621: ' ',\n",
       " 622: ' ',\n",
       " 623: ' ',\n",
       " 624: '   ',\n",
       " 625: ' -',\n",
       " 626: ' ',\n",
       " 627: ' ',\n",
       " 628: '   ',\n",
       " 629: ',  ',\n",
       " 630: ' , , ',\n",
       " 631: ' ',\n",
       " 632: '',\n",
       " 633: ' ',\n",
       " 634: '',\n",
       " 635: '   ',\n",
       " 636: ' ',\n",
       " 637: ' ',\n",
       " 638: ' ',\n",
       " 639: ' ',\n",
       " 640: ' ',\n",
       " 641: '   ',\n",
       " 642: ' ',\n",
       " 643: '',\n",
       " 644: '  ',\n",
       " 645: '   ',\n",
       " 646: ' ',\n",
       " 647: '  ',\n",
       " 648: '  ',\n",
       " 649: ' ',\n",
       " 650: ' ',\n",
       " 651: '  ',\n",
       " 652: ' ',\n",
       " 653: '   ',\n",
       " 654: '',\n",
       " 655: ' ',\n",
       " 656: ' ',\n",
       " 657: '  ',\n",
       " 658: '   ',\n",
       " 659: ' ',\n",
       " 660: ' ,  ',\n",
       " 661: ', ',\n",
       " 662: '  ',\n",
       " 663: ' ',\n",
       " 664: ' ',\n",
       " 665: ' ',\n",
       " 666: '  ',\n",
       " 667: '  ',\n",
       " 668: ' ',\n",
       " 669: ' ',\n",
       " 670: ' ',\n",
       " 671: '',\n",
       " 672: ' ',\n",
       " 673: ' ',\n",
       " 674: ' ',\n",
       " 675: '   ',\n",
       " 676: '   ',\n",
       " 677: '  ',\n",
       " 678: ' -',\n",
       " 679: ' ',\n",
       " 680: ' ',\n",
       " 681: '   ',\n",
       " 682: '  ',\n",
       " 683: ' ',\n",
       " 684: '  ',\n",
       " 685: ' ',\n",
       " 686: ' ',\n",
       " 687: '  ',\n",
       " 688: ' ',\n",
       " 689: ' ',\n",
       " 690: '',\n",
       " 691: '  ',\n",
       " 692: '    ',\n",
       " 693: ', , ',\n",
       " 694: ' ',\n",
       " 695: ' ',\n",
       " 696: '  ',\n",
       " 697: '   ',\n",
       " 698: '   ',\n",
       " 699: ' ',\n",
       " 700: '',\n",
       " 701: ' ',\n",
       " 702: '-',\n",
       " 703: '',\n",
       " 704: '  ',\n",
       " 705: '-',\n",
       " 706: ' ',\n",
       " 707: ' ',\n",
       " 708: ' ',\n",
       " 709: ' ',\n",
       " 710: '   ',\n",
       " 711: ' ',\n",
       " 712: ' ',\n",
       " 713: '  ',\n",
       " 714: '',\n",
       " 715: '',\n",
       " 716: ' ',\n",
       " 717: ' ',\n",
       " 718: ' ',\n",
       " 719: '   ',\n",
       " 720: '  ',\n",
       " 721: '',\n",
       " 722: '   ',\n",
       " 723: ' ,  ',\n",
       " 724: '- ',\n",
       " 725: '  ',\n",
       " 726: '-',\n",
       " 727: ' ',\n",
       " 728: ' ',\n",
       " 729: '',\n",
       " 730: ' ',\n",
       " 731: ' ',\n",
       " 732: '-  ',\n",
       " 733: ' ',\n",
       " 734: ' ',\n",
       " 735: ' ',\n",
       " 736: ' ',\n",
       " 737: '  ',\n",
       " 738: ' ',\n",
       " 739: '  ',\n",
       " 740: '   ',\n",
       " 741: '   ',\n",
       " 742: '',\n",
       " 743: '  ',\n",
       " 744: '   ',\n",
       " 745: '   ',\n",
       " 746: ' ',\n",
       " 747: ' ',\n",
       " 748: ' ',\n",
       " 749: '',\n",
       " 750: '   ',\n",
       " 751: '  ',\n",
       " 752: ' ',\n",
       " 753: '  ',\n",
       " 754: '',\n",
       " 755: '',\n",
       " 756: ', , ',\n",
       " 757: ' ',\n",
       " 758: '    ',\n",
       " 759: '   ',\n",
       " 760: ' ',\n",
       " 761: ' ,  ',\n",
       " 762: ' ',\n",
       " 763: '',\n",
       " 764: '',\n",
       " 765: ' ',\n",
       " 766: ' ',\n",
       " 767: '  ',\n",
       " 768: ' ',\n",
       " 769: '   ',\n",
       " 770: ' ',\n",
       " 771: '  ',\n",
       " 772: ' ',\n",
       " 773: ' ',\n",
       " 774: '  -',\n",
       " 775: '  ',\n",
       " 776: ' ',\n",
       " 777: '',\n",
       " 778: '',\n",
       " 779: '  ',\n",
       " 780: ' ',\n",
       " 781: '',\n",
       " 782: '  ',\n",
       " 783: ' ',\n",
       " 784: ' ',\n",
       " 785: ' ',\n",
       " 786: '-',\n",
       " 787: ' ',\n",
       " 788: ' ',\n",
       " 789: ' ',\n",
       " 790: '',\n",
       " 791: ',  ',\n",
       " 792: '',\n",
       " 793: ' ',\n",
       " 794: '',\n",
       " 795: '',\n",
       " 796: '    ',\n",
       " 797: ' ',\n",
       " 798: ' ',\n",
       " 799: '  ',\n",
       " 800: '   ',\n",
       " 801: ' ',\n",
       " 802: ' ',\n",
       " 803: '   ',\n",
       " 804: '',\n",
       " 805: ' ',\n",
       " 806: ' ',\n",
       " 807: '',\n",
       " 808: '  ',\n",
       " 809: '  ',\n",
       " 810: ' ',\n",
       " 811: ' ',\n",
       " 812: ' ',\n",
       " 813: ' ',\n",
       " 814: '',\n",
       " 815: ' ',\n",
       " 816: ' ',\n",
       " 817: ' ',\n",
       " 818: ' ',\n",
       " 819: ' ',\n",
       " 820: '',\n",
       " 821: ' ',\n",
       " 822: '   ',\n",
       " 823: '  ',\n",
       " 824: ' ',\n",
       " 825: ' ',\n",
       " 826: ' ',\n",
       " 827: '   ',\n",
       " 828: ' ',\n",
       " 829: '    ',\n",
       " 830: '',\n",
       " 831: '',\n",
       " 832: ' ',\n",
       " 833: '  ',\n",
       " 834: '  ',\n",
       " 835: '   ',\n",
       " 836: '    ',\n",
       " 837: ' ',\n",
       " 838: '  ',\n",
       " 839: '',\n",
       " 840: '    ',\n",
       " 841: '   ',\n",
       " 842: '  ',\n",
       " 843: '',\n",
       " 844: ' ',\n",
       " 845: ',    ',\n",
       " 846: ' ',\n",
       " 847: '',\n",
       " 848: ' ',\n",
       " 849: '   ',\n",
       " 850: '  ',\n",
       " 851: '',\n",
       " 852: '',\n",
       " 853: ', ',\n",
       " 854: '',\n",
       " 855: ' ',\n",
       " 856: '   ',\n",
       " 857: '  ',\n",
       " 858: '',\n",
       " 859: ' ',\n",
       " 860: '',\n",
       " 861: '-',\n",
       " 862: '  ',\n",
       " 863: '  ',\n",
       " 864: ' ',\n",
       " 865: '   ',\n",
       " 866: '  ',\n",
       " 867: '',\n",
       " 868: '',\n",
       " 869: ' ',\n",
       " 870: ' ',\n",
       " 871: ' ',\n",
       " 872: '',\n",
       " 873: '   ',\n",
       " 874: '',\n",
       " 875: '',\n",
       " 876: ' ',\n",
       " 877: '   ',\n",
       " 878: '',\n",
       " 879: ' ',\n",
       " 880: '',\n",
       " 881: '  ',\n",
       " 882: '    ',\n",
       " 883: ' ',\n",
       " 884: ' ',\n",
       " 885: ' ',\n",
       " 886: '',\n",
       " 887: ' ',\n",
       " 888: ' ',\n",
       " 889: '   ',\n",
       " 890: '  ',\n",
       " 891: '     ',\n",
       " 892: '',\n",
       " 893: ' ',\n",
       " 894: '-',\n",
       " 895: '  ',\n",
       " 896: '',\n",
       " 897: ' ',\n",
       " 898: ' ',\n",
       " 899: '  ',\n",
       " 900: '  ',\n",
       " 901: ' ',\n",
       " 902: '  ',\n",
       " 903: ' ',\n",
       " 904: ' ',\n",
       " 905: '',\n",
       " 906: '',\n",
       " 907: '   ',\n",
       " 908: ' ',\n",
       " 909: ' ',\n",
       " 910: ' ',\n",
       " 911: ' ',\n",
       " 912: '',\n",
       " 913: ' ',\n",
       " 914: ' ',\n",
       " 915: '',\n",
       " 916: ' ',\n",
       " 917: ' ',\n",
       " 918: '  ',\n",
       " 919: ' ',\n",
       " 920: ' ',\n",
       " 921: '',\n",
       " 922: '  ',\n",
       " 923: '   ',\n",
       " 924: ' ',\n",
       " 925: '',\n",
       " 926: ' ',\n",
       " 927: ' ',\n",
       " 928: ' ',\n",
       " 929: '     ',\n",
       " 930: '',\n",
       " 931: ' ',\n",
       " 932: '',\n",
       " 933: '',\n",
       " 934: ' ',\n",
       " 935: '   ',\n",
       " 936: '  ',\n",
       " 937: '  ',\n",
       " 938: '   ',\n",
       " 939: '  ',\n",
       " 940: ' ',\n",
       " 941: '   ',\n",
       " 942: '    ',\n",
       " 943: '-',\n",
       " 944: ' ',\n",
       " 945: '-',\n",
       " 946: ' ',\n",
       " 947: '   ',\n",
       " 948: ',  ',\n",
       " 949: ' ',\n",
       " 950: ' ',\n",
       " 951: ' ',\n",
       " 952: '  ',\n",
       " 953: ' ',\n",
       " 954: ' ',\n",
       " 955: '',\n",
       " 956: '',\n",
       " 957: ' ',\n",
       " 958: ' ',\n",
       " 959: '',\n",
       " 960: '     ',\n",
       " 961: ' ',\n",
       " 962: '   ',\n",
       " 963: '   ',\n",
       " 964: ' ',\n",
       " 965: '   ',\n",
       " 966: '',\n",
       " 967: ' ',\n",
       " 968: ' ',\n",
       " 969: '  ',\n",
       " 970: ' ',\n",
       " 971: ' ',\n",
       " 972: '   ',\n",
       " 973: '  ',\n",
       " 974: ' , , ',\n",
       " 975: '    ',\n",
       " 976: '  ',\n",
       " 977: '',\n",
       " 978: ' ',\n",
       " 979: ' ',\n",
       " 980: '',\n",
       " 981: '  ',\n",
       " 982: ' ',\n",
       " 983: ' ',\n",
       " 984: ' ',\n",
       " 985: '   ',\n",
       " 986: '   ',\n",
       " 987: ' ',\n",
       " 988: ' ',\n",
       " 989: '  ',\n",
       " 990: ' ',\n",
       " 991: ' ',\n",
       " 992: ' ',\n",
       " 993: ' ',\n",
       " 994: '',\n",
       " 995: '',\n",
       " 996: '   ',\n",
       " 997: ' ',\n",
       " 998: ' ',\n",
       " 999: '  ',\n",
       " ...}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real_y_by_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classificaton_model.load_weights(\"logs_classification_lr=0.0001/epoch_3_batch_7620.h5py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
