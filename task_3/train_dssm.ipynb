{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix\n",
    "import re\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "from IPython.display import clear_output\n",
    "from collections import defaultdict\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"3\"\n",
    "\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Embedding, LSTM, Bidirectional, Dense, Input, Masking, Lambda\n",
    "import keras.backend as K\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import LambdaCallback, LearningRateScheduler, Callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_max_lens(filename):\n",
    "    max_query_len, max_document_len = -1, -1\n",
    "    with open(filename) as handler:\n",
    "        for line in handler:\n",
    "            query, document = line.split(\"\\t\")\n",
    "            query_len = len(query.split())\n",
    "            document_len = len(document.split())\n",
    "            if query_len > max_query_len:\n",
    "                max_qu\n",
    "                ery_len = query_len\n",
    "            if document_len > max_document_len:\n",
    "                max_document_len = document_len\n",
    "    return max_query_len, max_document_len\n",
    "\n",
    "def cycle_file(filename):\n",
    "    while True:\n",
    "        with open(filename) as f:\n",
    "            yield from f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#max_query_len, max_document_len = get_max_lens(TRAIN_DATA)\n",
    "max_document_len, max_query_len = (35840, 1475)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "DATA_SIZE = 500000\n",
    "QUERY_DICT_SIZE = 247074\n",
    "DOCUMENT_DICT_SIZE = 583954\n",
    "ACTIVATION = 'relu'\n",
    "HIDDEN_SIZE = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_seq_batches_generator(filename, batch_size, max_query_len, max_document_len):\n",
    "    with open(filename) as handler:\n",
    "        while True:\n",
    "            query_batch = np.zeros([batch_size, max_query_len])\n",
    "            docment_batch = np.zeros([batch_size, max_document_len])\n",
    "            for i in range(batch_size):\n",
    "                line = next(handler)\n",
    "                query, document = line.split(\"\\t\")\n",
    "                query = list(map(int, query.split()))\n",
    "                document = list(map(int, document.split()))\n",
    "                query_batch[i, :len(query)] = query\n",
    "                docment_batch[i, :len(document)] = document\n",
    "            yield query_batch, docment_batch\n",
    "\n",
    "def make_non_seq_batches_generator(filename, batch_size):\n",
    "    with open(filename) as handler:\n",
    "        while True:\n",
    "            query_batch = np.zeros([batch_size, QUERY_DICT_SIZE])\n",
    "            docment_batch = np.zeros([batch_size, DOCUMENT_DICT_SIZE])\n",
    "            for i in range(batch_size):\n",
    "                line = next(handler)\n",
    "                query, document = line.split(\"\\t\")\n",
    "                query = list(map(int, query.split()))\n",
    "                document = list(map(int, document.split()))\n",
    "                for word in query:\n",
    "                    query_batch[i, word] +=1\n",
    "                for word in document:\n",
    "                    docment_batch[i, word] +=1\n",
    "            yield query_batch, docment_batch\n",
    "\n",
    "def make_data_generator(positive_generator, negative_generator):\n",
    "    while True:\n",
    "        positive_query_batch, positive_docment_batch = next(positive_generator)\n",
    "        negative_query_batch, negative_docment_batch = next(negative_generator)\n",
    "        query_input = np.concatenate([positive_query_batch, negative_query_batch], axis=0)\n",
    "        document_input = np.concatenate([positive_docment_batch, negative_docment_batch], axis=0)\n",
    "        labels = np.concatenate(\n",
    "            [np.ones(len(positive_query_batch)), -1 * np.ones(len(negative_query_batch))\n",
    "        ]).reshape([-1, 1])\n",
    "        yield (\n",
    "            {'query_input': query_input, 'document_input': document_input},\n",
    "            {'output': labels}\n",
    "        )\n",
    "\n",
    "def make_sparse_data_generator(positive_filename, negative_filename, batch_size):\n",
    "    with open(positive_filename) as positive_handler, open(negative_filename) as negative_handler:\n",
    "        while True:\n",
    "            query_indices_axis_0, document_indices_axis_0 = [], []\n",
    "            query_indices_axis_1, document_indices_axis_1 = [], []\n",
    "            query_values, document_values = [], []\n",
    "            for handler in [positive_handler, negative_handler]:\n",
    "                for i in range(batch_size):\n",
    "                    line = next(handler)\n",
    "                    query, document = line.split(\"\\t\")\n",
    "                    query_words = Counter(map(int, query.split()))\n",
    "                    document_words = Counter(map(int, document.split()))\n",
    "\n",
    "                    for word in query_words:\n",
    "                        query_indices_axis_0.append(i)\n",
    "                        query_indices_axis_1.append(word)\n",
    "                        query_values.append(query_words[word])\n",
    "                    for word in document_words:\n",
    "                        document_indices_axis_0.append(i)\n",
    "                        document_indices_axis_1.append(word)\n",
    "                        document_values.append(document_words[word])\n",
    "                    \n",
    "            query_batch = csr_matrix(\n",
    "                (query_values, (query_indices_axis_0, query_indices_axis_1)),\n",
    "                shape=(BATCH_SIZE * 2, QUERY_DICT_SIZE)\n",
    "            )\n",
    "            docment_batch = csr_matrix(\n",
    "                (document_values, (document_indices_axis_0, document_indices_axis_1)),\n",
    "                shape=(BATCH_SIZE * 2, DOCUMENT_DICT_SIZE)\n",
    "            )\n",
    "            labels = np.concatenate([np.ones(batch_size), -1 * np.ones(batch_size)]).reshape([-1, 1])\n",
    "            yield (\n",
    "                {'query_input': query_batch, 'document_input': docment_batch},\n",
    "                {'output': labels}\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_cosine_proximity(y_true, y_pred):\n",
    "    return -K.mean(y_pred * y_true)\n",
    "\n",
    "def mean_positive_score(y_true, y_pred):\n",
    "    filter_mult = (y_true + 1) / 2\n",
    "    return K.mean(y_pred * filter_mult)\n",
    "\n",
    "def mean_positive_var(y_true, y_pred):\n",
    "    mean_positive = mean_positive_score(y_true, y_pred)\n",
    "    filter_mult = (y_true + 1) / 2\n",
    "    return K.mean((y_pred * filter_mult - mean_positive) ** 2)\n",
    "\n",
    "def get_pred(y_true, y_pred):\n",
    "    mean_positive = mean_positive_score(y_true, y_pred)\n",
    "    mean_negative = mean_negative_score(y_true, y_pred)\n",
    "    \n",
    "    threshold = (mean_positive + mean_negative) / 2\n",
    "    \n",
    "    positive_mult = (y_true + 1) / 2\n",
    "    negative_mult = (1 - y_true) / 2\n",
    "\n",
    "    return K.mean((y_pred * filter_mult - mean_positive) ** 2)\n",
    "\n",
    "def mean_negative_score(y_true, y_pred):\n",
    "    filter_mult = (1 - y_true) / 2\n",
    "    return K.mean(y_pred * filter_mult)\n",
    "\n",
    "def mean_negative_var(y_true, y_pred):\n",
    "    mean_negative = mean_negative_score(y_true, y_pred)\n",
    "    filter_mult = (1 - y_true) / 2\n",
    "    return K.mean((y_pred * filter_mult - mean_negative) ** 2)\n",
    "\n",
    "def normalize(embedding):\n",
    "    return K.l2_normalize(embedding, axis=-1)\n",
    "\n",
    "def dot_product(embeddings):\n",
    "    return K.sum(embeddings[0] * embeddings[1], axis=-1)\n",
    "\n",
    "def reshape_to_prediction(score):\n",
    "    return K.reshape(score, (-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_lstm_branch(tensor, lstm_num, dense_num, hidden_size, dict_size, activation):\n",
    "    tensor = Masking(mask_value=0)(tensor)\n",
    "    tensor = Embedding(dict_size, hidden_size)(tensor)  # shape: (BATCH_SIZE, dict_size, hidden_size)\n",
    "    for i in range(lstm_num - 1):\n",
    "        tensor = Bidirectional(LSTM(hidden_size, return_sequences=True))(tensor)  # shape: (BATCH_SIZE, hidden_size)\n",
    "    tensor = Bidirectional(LSTM(hidden_size))(tensor)  # shape: (BATCH_SIZE, hidden_size)\n",
    "    for i in range(dense_num):\n",
    "        tensor = Dense(hidden_size, activation=activation)(tensor)  # shape: (BATCH_SIZE, hidden_size)\n",
    "    return Lambda(normalize)(tensor)  # shape: (BATCH_SIZE, hidden_size)\n",
    "\n",
    "def make_dense_branch(tensor, dense_num, hidden_size, dict_size, activation):\n",
    "    for i in range(dense_num):\n",
    "        tensor = Dense(hidden_size, activation=activation)(tensor)  # shape: (BATCH_SIZE, hidden_size)\n",
    "    return Lambda(normalize)(tensor)  # shape: (BATCH_SIZE, hidden_size)\n",
    "\n",
    "def make_compiled_model(input_1, input_2, embedding_1, embedding_2):\n",
    "    score = Lambda(dot_product)([embedding_1, embedding_2])\n",
    "    prediction = Lambda(reshape_to_prediction, name=\"output\")(score)\n",
    "\n",
    "    model = Model(inputs=[input_1, input_2], outputs=prediction)\n",
    "    model.compile(\n",
    "        Adam(),\n",
    "        loss=my_cosine_proximity,\n",
    "        metrics=[mean_positive_score, mean_negative_score, mean_positive_var, mean_negative_var, 'acc']\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dense_model(document_dict_size,\n",
    "                     document_dense_num,\n",
    "                     query_dict_size,\n",
    "                     query_dense_num,\n",
    "                     activation,\n",
    "                     hidden_size):\n",
    "    # shape: (BATCH_SIZE, QUERY_DICT_SIZE)\n",
    "    query_input = Input(shape=(query_dict_size,), sparse=True, name=\"query_input\")\n",
    "    query_embedding = make_dense_branch(\n",
    "        query_input,\n",
    "        query_dense_num,\n",
    "        hidden_size,\n",
    "        query_dict_size,\n",
    "        activation\n",
    "    )\n",
    "    \n",
    "    # shape: (BATCH_SIZE, document_dict_size)\n",
    "    document_input = Input(shape=(document_dict_size,), sparse=True, name=\"document_input\")\n",
    "    document_embedding = make_dense_branch(\n",
    "        document_input,\n",
    "        document_dense_num,\n",
    "        hidden_size,\n",
    "        document_dict_size,\n",
    "        activation\n",
    "    )\n",
    "\n",
    "    return make_compiled_model(query_input, document_input, query_embedding, document_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dense_model = make_dense_model(\n",
    "    DOCUMENT_DICT_SIZE,\n",
    "    2,\n",
    "    QUERY_DICT_SIZE,\n",
    "    2,\n",
    "    ACTIVATION,\n",
    "    HIDDEN_SIZE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "history = dense_model.fit_generator(\n",
    "    make_sparse_data_generator(\"positive_train_data_35K.tsv\", \"negative_train_data_35K.tsv\", BATCH_SIZE),\n",
    "    steps_per_epoch=int(DATA_SIZE / (BATCH_SIZE * 2)),\n",
    "    epochs=10,\n",
    "    verbose=1,\n",
    "    initial_epoch=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_gen = make_non_seq_batches_generator(\"positive_train_data_35K.tsv\", 1)\n",
    "negative_gen = make_non_seq_batches_generator(\"negative_train_data_35K.tsv\", 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_q, p_d = next(positive_gen)\n",
    "n_q, n_d = next(negative_gen)\n",
    "(\n",
    "    dense_model.predict({\"document_input\": p_d, \"query_input\": p_q})[0, 0],\n",
    "    dense_model.predict({\"document_input\": n_d, \"query_input\": n_q})[0, 0]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_q, p_d = next(positive_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(p_q.toarray()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = make_sparse_data_generator(\"positive_train_data_35K.tsv\", \"negative_train_data_35K.tsv\", BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = next(gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
